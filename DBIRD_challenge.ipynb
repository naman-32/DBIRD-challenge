{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DBIRD challenge",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYItBF5gdj7O",
        "colab_type": "text"
      },
      "source": [
        "# Baseline for [DIBRD Challenge](https://www.aicrowd.com/challenges/aicrowd-blitz-may-2020/problems/dibrd) on AIcrowd\n",
        "#### Author : Naman Goenka\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpvXuq6qdj7Q",
        "colab_type": "text"
      },
      "source": [
        "## To open this notebook on Google Computing platform Colab, click below!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS_im-Q9dj7R",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/aicrowd-bot/761175b71c995e5a44a0877daf9e0597)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySCQPjUddj7T",
        "colab_type": "text"
      },
      "source": [
        "## Download Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4jaoeUPdj7U",
        "colab_type": "code",
        "outputId": "df6eb542-d067-4967-8c04-27a7690579f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy\n",
        "!{sys.executable} -m pip install pandas\n",
        "!{sys.executable} -m pip install scikit-learn\n",
        "!{sys.executable} -m pip install keras\n",
        "!{sys.executable} -m pip install matplotlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NVc6hrbdj7c",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtLALoRdj7f",
        "colab_type": "text"
      },
      "source": [
        "The first step is to download out train test data. We will be training a classifier on the train data and make predictions on test data. We submit our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWMTLVl1dj7h",
        "colab_type": "code",
        "outputId": "db140137-011e-42a0-df52-e0996b38ee0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/dibrd/v0.1/train.csv -O data/train.csv\n",
        "!wget https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/dibrd/v0.1/test.csv -O data/test.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 12:22:12--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/dibrd/v0.1/train.csv\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.12, 130.117.252.13, 130.117.252.16, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116826 (114K) [text/csv]\n",
            "Saving to: ‘data/train.csv’\n",
            "\n",
            "data/train.csv      100%[===================>] 114.09K   352KB/s    in 0.3s    \n",
            "\n",
            "2020-05-15 12:22:13 (352 KB/s) - ‘data/train.csv’ saved [116826/116826]\n",
            "\n",
            "--2020-05-15 12:22:15--  https://s3.eu-central-1.wasabisys.com/aicrowd-practice-challenges/public/dibrd/v0.1/test.csv\n",
            "Resolving s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)... 130.117.252.12, 130.117.252.13, 130.117.252.10, ...\n",
            "Connecting to s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29188 (29K) [text/csv]\n",
            "Saving to: ‘data/test.csv’\n",
            "\n",
            "data/test.csv       100%[===================>]  28.50K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-15 12:22:15 (265 KB/s) - ‘data/test.csv’ saved [29188/29188]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvUaDzqHdj7n",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8RRAQSdj7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
        "from keras.layers import Dense, Input, Dropout , InputLayer\n",
        "from keras import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZHEXBXdj7u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Load Train Data\n",
        "We use pandas library to load our data. Pandas loads them into dataframes which helps us analyze our data easily. Learn more about it [here](https://www.tutorialspoint.com/python_data_science/python_pandas.htm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlst6Z12VD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2VhTv8Zdj7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = \"data/train.csv\" #path where data is stored"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XMvfxTndj73",
        "colab_type": "code",
        "outputId": "8f33a6f3-cf02-4e25-b0d2-d810aaa6ff61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "col_names = ['bn_ql', 'bn_prs', 'm_0.5','m_0.6','m_0.7','m_0.8','m_0.9','m_1.0',\n",
        "             'nex.a','nex.b','nex.c','nex.d','nex.e','nex.f','nex.g','nex.h',\n",
        "             'nrm_ed_ds','diam','bn_am/fm','label'\n",
        "            ]\n",
        "train_data = pd.read_csv(train_data_path,names=col_names,header=None) #load data in dataframe using pandas\n",
        "print(len(col_names))\n",
        "print(train_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "(920, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o51rwfSPdj89",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Set\n",
        "Load the test data now# Load the evaluation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z7mIaVjdj8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test_path = \"data/test.csv\"\n",
        "final_test = pd.read_csv(final_test_path,header=None,names = col_names[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUYial6dj78",
        "colab_type": "text"
      },
      "source": [
        "## Visualise the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee_Hrofmdj7-",
        "colab_type": "code",
        "outputId": "cee9e4fb-93e8-4d7f-bc3b-119b7052a80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(920, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bn_ql</th>\n",
              "      <th>bn_prs</th>\n",
              "      <th>m_0.5</th>\n",
              "      <th>m_0.6</th>\n",
              "      <th>m_0.7</th>\n",
              "      <th>m_0.8</th>\n",
              "      <th>m_0.9</th>\n",
              "      <th>m_1.0</th>\n",
              "      <th>nex.a</th>\n",
              "      <th>nex.b</th>\n",
              "      <th>nex.c</th>\n",
              "      <th>nex.d</th>\n",
              "      <th>nex.e</th>\n",
              "      <th>nex.f</th>\n",
              "      <th>nex.g</th>\n",
              "      <th>nex.h</th>\n",
              "      <th>nrm_ed_ds</th>\n",
              "      <th>diam</th>\n",
              "      <th>bn_am/fm</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>63</td>\n",
              "      <td>60</td>\n",
              "      <td>55</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>13.195493</td>\n",
              "      <td>4.396967</td>\n",
              "      <td>0.104070</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.513092</td>\n",
              "      <td>0.123966</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>72</td>\n",
              "      <td>69</td>\n",
              "      <td>50</td>\n",
              "      <td>61.559348</td>\n",
              "      <td>28.959444</td>\n",
              "      <td>12.778104</td>\n",
              "      <td>2.045287</td>\n",
              "      <td>0.038016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527993</td>\n",
              "      <td>0.101884</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>35</td>\n",
              "      <td>6.090116</td>\n",
              "      <td>0.834492</td>\n",
              "      <td>0.027460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.506881</td>\n",
              "      <td>0.091535</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>75.438535</td>\n",
              "      <td>20.352500</td>\n",
              "      <td>5.237412</td>\n",
              "      <td>0.206817</td>\n",
              "      <td>0.003884</td>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.544614</td>\n",
              "      <td>0.089329</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>59</td>\n",
              "      <td>57</td>\n",
              "      <td>48</td>\n",
              "      <td>13.558211</td>\n",
              "      <td>5.366467</td>\n",
              "      <td>0.604079</td>\n",
              "      <td>0.051511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552941</td>\n",
              "      <td>0.112387</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bn_ql  bn_prs  m_0.5  m_0.6  ...  nrm_ed_ds      diam  bn_am/fm  label\n",
              "0      1       1     75     63  ...   0.513092  0.123966         0      1\n",
              "1      1       1     79     76  ...   0.527993  0.101884         0      1\n",
              "2      1       1     41     41  ...   0.506881  0.091535         1      0\n",
              "3      1       1     17     16  ...   0.544614  0.089329         1      1\n",
              "4      1       1     63     63  ...   0.552941  0.112387         0      1\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctl8v0iPdj8F",
        "colab_type": "text"
      },
      "source": [
        "You can see the columns goes from 0 to 19, where columns from 0 to 18 represents features extracted from the image set and last column represents the type of patient i.e 1 if if signs of Diabetic Retinopathy is present else 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WagAa0ngNFfY",
        "colab_type": "code",
        "outputId": "9feb4681-2144-495e-b28e-5e77781bdb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(final_test.shape)\n",
        "final_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(230, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bn_ql</th>\n",
              "      <th>bn_prs</th>\n",
              "      <th>m_0.5</th>\n",
              "      <th>m_0.6</th>\n",
              "      <th>m_0.7</th>\n",
              "      <th>m_0.8</th>\n",
              "      <th>m_0.9</th>\n",
              "      <th>m_1.0</th>\n",
              "      <th>nex.a</th>\n",
              "      <th>nex.b</th>\n",
              "      <th>nex.c</th>\n",
              "      <th>nex.d</th>\n",
              "      <th>nex.e</th>\n",
              "      <th>nex.f</th>\n",
              "      <th>nex.g</th>\n",
              "      <th>nex.h</th>\n",
              "      <th>nrm_ed_ds</th>\n",
              "      <th>diam</th>\n",
              "      <th>bn_am/fm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>33</td>\n",
              "      <td>24</td>\n",
              "      <td>110.505328</td>\n",
              "      <td>36.711632</td>\n",
              "      <td>11.784233</td>\n",
              "      <td>2.122308</td>\n",
              "      <td>0.416480</td>\n",
              "      <td>0.044002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499970</td>\n",
              "      <td>0.093120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>68.002805</td>\n",
              "      <td>13.919028</td>\n",
              "      <td>5.614372</td>\n",
              "      <td>1.196826</td>\n",
              "      <td>0.610773</td>\n",
              "      <td>0.306931</td>\n",
              "      <td>0.179215</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>0.518665</td>\n",
              "      <td>0.093727</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>51.241067</td>\n",
              "      <td>19.732536</td>\n",
              "      <td>7.177703</td>\n",
              "      <td>0.441538</td>\n",
              "      <td>0.036385</td>\n",
              "      <td>0.006884</td>\n",
              "      <td>0.003934</td>\n",
              "      <td>0.002950</td>\n",
              "      <td>0.509862</td>\n",
              "      <td>0.092438</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>33</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>26</td>\n",
              "      <td>6.193941</td>\n",
              "      <td>1.625616</td>\n",
              "      <td>0.108061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.517101</td>\n",
              "      <td>0.084570</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>123.622304</td>\n",
              "      <td>34.630302</td>\n",
              "      <td>17.127238</td>\n",
              "      <td>3.043477</td>\n",
              "      <td>0.276494</td>\n",
              "      <td>0.070659</td>\n",
              "      <td>0.017409</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.554011</td>\n",
              "      <td>0.121862</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bn_ql  bn_prs  m_0.5  m_0.6  ...     nex.h  nrm_ed_ds      diam  bn_am/fm\n",
              "0      1       1     49     49  ...  0.000000   0.499970  0.093120         1\n",
              "1      1       1     16     14  ...  0.086518   0.518665  0.093727         0\n",
              "2      1       1     24     24  ...  0.002950   0.509862  0.092438         1\n",
              "3      1       1     35     33  ...  0.000000   0.517101  0.084570         0\n",
              "4      1       1     20     20  ...  0.013313   0.554011  0.121862         0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJfbrNyuombg",
        "colab_type": "text"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfTZJZlqom-F",
        "colab_type": "code",
        "outputId": "8e1d5033-2fac-425f-fe6c-1d91a6258bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# Ref:- https://machinelearningmastery.com/visualize-machine-learning-data-python-pandas/\n",
        "# and https://matplotlib.org/3.2.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n",
        "# Correction Matrix Plot\n",
        "\n",
        "correlations = train_data.corr()\n",
        "# plot correlation matrix\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = np.arange(0,20,1)\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(col_names)\n",
        "ax.set_yticklabels(col_names)\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=-45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyExsFu928ya",
        "colab_type": "text"
      },
      "source": [
        "# Univariate Density Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4QAy2GA27px",
        "colab_type": "code",
        "outputId": "55ebf1f2-e7da-436b-d302-c4df2d4a573e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "# Univariate Density Plots\n",
        "\n",
        "train_data.plot(kind='density', subplots=True, layout=(5,4), sharex=False)\n",
        "plt.show()\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb0W1D167iPM",
        "colab_type": "code",
        "outputId": "750d193e-f1a1-496e-d12e-1ba17eece3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "#train_data final_test\n",
        "\n",
        "\n",
        "y_train = train_data.iloc[:,-1] #values\n",
        "# train_data.head()\n",
        "train_data.drop(['label'], axis=1,inplace=True)\n",
        "\n",
        "num_train = len(train_data)\n",
        "\n",
        "df_all = pd.concat([train_data, final_test])\n",
        "\n",
        "# Scaling features\n",
        "scaler = RobustScaler()\n",
        "df_all = scaler.fit_transform(df_all)\n",
        "\n",
        "\n",
        "x_train    = pd.DataFrame(df_all[:num_train] , columns = col_names[:-1]) \n",
        "final_test = pd.DataFrame(df_all[num_train:] , columns = col_names[:-1]) \n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(final_test.shape)\n",
        "\n",
        "x_train.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(920, 19)\n",
            "(920,)\n",
            "(230, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bn_ql</th>\n",
              "      <th>bn_prs</th>\n",
              "      <th>m_0.5</th>\n",
              "      <th>m_0.6</th>\n",
              "      <th>m_0.7</th>\n",
              "      <th>m_0.8</th>\n",
              "      <th>m_0.9</th>\n",
              "      <th>m_1.0</th>\n",
              "      <th>nex.a</th>\n",
              "      <th>nex.b</th>\n",
              "      <th>nex.c</th>\n",
              "      <th>nex.d</th>\n",
              "      <th>nex.e</th>\n",
              "      <th>nex.f</th>\n",
              "      <th>nex.g</th>\n",
              "      <th>nex.h</th>\n",
              "      <th>nrm_ed_ds</th>\n",
              "      <th>diam</th>\n",
              "      <th>bn_am/fm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025641</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>-0.473352</td>\n",
              "      <td>-0.540210</td>\n",
              "      <td>-0.409905</td>\n",
              "      <td>-0.261301</td>\n",
              "      <td>-0.116049</td>\n",
              "      <td>-0.040270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250585</td>\n",
              "      <td>0.727250</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.128205</td>\n",
              "      <td>1.108108</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>1.264706</td>\n",
              "      <td>1.37500</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.264237</td>\n",
              "      <td>0.510662</td>\n",
              "      <td>0.793344</td>\n",
              "      <td>0.847606</td>\n",
              "      <td>0.081577</td>\n",
              "      <td>-0.040270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114685</td>\n",
              "      <td>-0.198775</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>-0.581715</td>\n",
              "      <td>-0.692625</td>\n",
              "      <td>-0.417178</td>\n",
              "      <td>-0.261301</td>\n",
              "      <td>-0.116049</td>\n",
              "      <td>-0.040270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.402836</td>\n",
              "      <td>-0.632769</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.461538</td>\n",
              "      <td>-0.513514</td>\n",
              "      <td>-0.444444</td>\n",
              "      <td>-0.441176</td>\n",
              "      <td>-0.40625</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.475907</td>\n",
              "      <td>0.142426</td>\n",
              "      <td>0.077445</td>\n",
              "      <td>-0.149170</td>\n",
              "      <td>-0.095858</td>\n",
              "      <td>-0.015051</td>\n",
              "      <td>0.200869</td>\n",
              "      <td>0.252191</td>\n",
              "      <td>0.522117</td>\n",
              "      <td>-0.725279</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>-0.467820</td>\n",
              "      <td>-0.498731</td>\n",
              "      <td>-0.362435</td>\n",
              "      <td>-0.233373</td>\n",
              "      <td>-0.116049</td>\n",
              "      <td>-0.040270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.726238</td>\n",
              "      <td>0.241676</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bn_ql  bn_prs     m_0.5     m_0.6  ...     nex.h  nrm_ed_ds      diam  bn_am/fm\n",
              "0    0.0     0.0  1.025641  0.756757  ...  0.000000  -0.250585  0.727250       0.0\n",
              "1    0.0     0.0  1.128205  1.108108  ...  0.000000   0.114685 -0.198775       0.0\n",
              "2    0.0     0.0  0.153846  0.162162  ...  0.000000  -0.402836 -0.632769       1.0\n",
              "3    0.0     0.0 -0.461538 -0.513514  ...  0.252191   0.522117 -0.725279       1.0\n",
              "4    0.0     0.0  0.717949  0.756757  ...  0.000000   0.726238  0.241676       0.0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEBNOV1gdj8G",
        "colab_type": "text"
      },
      "source": [
        "## Split Data into Train and Validation\n",
        "Now we want to see how well our classifier is performing, but we dont have the test data labels with us to check. What do we do ? So we split our dataset into train and validation. The idea is that we test our classifier on validation set in order to get an idea of how well our classifier works. This way we can also ensure that we dont [overfit](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/) on the train dataset. There are many ways to do validation like [k-fold](https://machinelearningmastery.com/k-fold-cross-validation/),[leave one out](https://en.wikipedia.org/wiki/Cross-validation_(statistics), etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn94b1vTdj8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_val= train_test_split(train_data, test_size=0.2, random_state=42) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzhucvVidj8L",
        "colab_type": "text"
      },
      "source": [
        "Here we have selected the size of the testing data to be 20% of the total data. You can change it and see what effect it has on the accuracies. To learn more about the train_test_split function [click here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB-vZDg8dj8M",
        "colab_type": "text"
      },
      "source": [
        "Now, since we have our data splitted into train and validation sets, we need to get the label separated from the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5u8CbMWdj8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train,y_train = X_train.iloc[:,:-1],X_train.iloc[:,-1]\n",
        "# X_val,y_val = X_val.iloc[:,:-1],X_val.iloc[:,-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G47xRBxdj8T",
        "colab_type": "text"
      },
      "source": [
        "## Define the Classifier\n",
        "Now we come to the juicy part. We have fixed our data and now we train a classifier. The classifier will learn the function by looking at the inputs and corresponding outputs. There are a ton of classifiers to choose from some being [Logistic Regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc), [SVM](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Random Forests](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Decision Trees](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052), etc.   \n",
        "Tip: A good model doesnt depend solely on the classifier but on the features(columns) you choose. So make sure to play with your data and keep only whats important. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZrp9Asldj8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier = LogisticRegression(solver = 'lbfgs',multi_class='auto',max_iter=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERDZ4oaIdj8a",
        "colab_type": "text"
      },
      "source": [
        "We have used [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) as a classifier here and set few of the parameteres. But one can set more parameters and increase the performance. To see the list of parameters visit [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "268RA8aJdj8b",
        "colab_type": "text"
      },
      "source": [
        "We can also use other classifiers. To read more about sklean classifiers visit [here](https://scikit-learn.org/stable/supervised_learning.html). Try and use other classifiers to see how the performance of your model changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa27NN7Xdj8d",
        "colab_type": "text"
      },
      "source": [
        "## Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miPxc9TFdj8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo_3H5UGdj8o",
        "colab_type": "text"
      },
      "source": [
        "Got a warning! Dont worry, its just beacuse the number of iteration is very less(defined in the classifier in the above cell).Increase the number of iterations and see if the warning vanishes and also see how the performance changes.Do remember increasing iterations also increases the running time.( Hint: max_iter=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VCAIhaUdj8p",
        "colab_type": "text"
      },
      "source": [
        "## Predict on Validation\n",
        "Now we predict our trained classifier on the validation set and evaluate our model# Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00zHAec9dj8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_pred = classifier.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz6Mtnukhb9M",
        "colab_type": "text"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5M9wFyhbjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# lsvc = LinearSVC(C=0.05, penalty=\"l1\", dual=False, max_iter = 1000).fit(x_train, y_train)\n",
        "# model = SelectFromModel(lsvc, prefit=True)\n",
        "# x_train_new = model.transform(x_train)\n",
        "# final_test_new = model.transform(final_test)\n",
        "\n",
        "\n",
        "# feature_idx  = model.get_support()\n",
        "# feature_name = x_train.columns[feature_idx]\n",
        "\n",
        "# x_train_new.shape\n",
        "# final_test_new.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6B9NcoPwpkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train_new    = pd.DataFrame(x_train_new   , columns = feature_name) \n",
        "# final_test_new = pd.DataFrame(final_test_new, columns = feature_name)\n",
        "# x_train_new.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssSPgLpIdXl3",
        "colab_type": "text"
      },
      "source": [
        "### ## TUNING batch size and epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1rvJsU0dXyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_model(dense_layer_sizes= [], optimizer=\"adam\", dropout=0.1, init='uniform', nbr_features=19):#dense_nparams=10):\n",
        "#     model = Sequential()\n",
        "#     model.add(InputLayer(input_shape=(nbr_features,),))\n",
        "\n",
        "#     hid_lay = 1\n",
        "#     if not type(dense_layer_sizes) == type( (0,1) ): \n",
        "#       dense_layer_sizes = (dense_layer_sizes,)\n",
        "#     # for error TypeError: 'int' object is not iterable\n",
        "\n",
        "\n",
        "#     for layer_size in dense_layer_sizes:\n",
        "#         if hid_lay == 1:\n",
        "#           model.add(Dense(layer_size, activation='relu',  kernel_initializer=init,)) \n",
        "#           model.add(Dropout(dropout), )\n",
        "#           hid_lay+=1\n",
        "#         else:\n",
        "#           model.add(Dense(layer_size, activation='relu'))\n",
        "#           model.add(Dropout(dropout), )\n",
        "#           hid_lay+=1\n",
        "#     model.add(Dense(1, activation='sigmoid'))\n",
        "#     model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\",\"mae\"])\n",
        "#     return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 19,kernel_initializer = 'uniform',activation = 'relu'))\n",
        "    # model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(4,input_dim = 8,kernel_initializer =  'uniform',activation = 'relu'))\n",
        "    # model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy','mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# def build_model_fn(neurons=20, noise=0.25):\n",
        "#     model = Sequential()\n",
        "#     model.add(InputLayer(input_shape=(train.shape[1],)))\n",
        "#     model.add(GaussianNoise(noise))\n",
        "#     model.add(Dense(neurons, activation='tanh'))\n",
        "#     model.add(Dense(1, activation='linear'))\n",
        "#     model.compile(loss='mean_squared_error', optimizer='nadam', metrics=[r2_keras])\n",
        "#     return model\n",
        "\n",
        "kears_estimator = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "cnf = Pipeline([ \n",
        "                # ('feature_selection', SelectFromModel(LinearSVC(C=0.07, penalty=\"l1\", dual=False, max_iter = 1000))),\n",
        "                     \n",
        "                       (\"kc\", kears_estimator),\n",
        "                ])\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid = {\n",
        "    # 'kc__dense_layer_sizes' : [ (12), (12,4),(8),(8,4),(10),(10,4) ],\n",
        "    'kc__epochs': [10,50,100, ],\n",
        "    # 'kc__dense_nparams': [12, 8, 10],\n",
        "    # 'kc__init': [ 'uniform', 'zeros', 'normal', ], \n",
        "    'kc__batch_size':[2, 16, 32, 46 , 64],\n",
        "    # 'kc__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
        "    # 'kc__dropout': [0.5, 0.4, 0.3, 0.2, 0.1, 0]\n",
        "}\n",
        "\n",
        "kfold_splits = 5\n",
        "grid = GridSearchCV(estimator=cnf,  \n",
        "                    n_jobs=-1, \n",
        "                    verbose=10,\n",
        "                    return_train_score=True,\n",
        "                    cv=kfold_splits,  \n",
        "                    param_grid=param_grid,\n",
        "                    scoring = 'f1',\n",
        "                  )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVjnu4Q6TUz3",
        "colab_type": "text"
      },
      "source": [
        "### Using Grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFUBL60aTRnZ",
        "colab_type": "code",
        "outputId": "bc75cba0-04d1-429f-e363-0723d967aead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_result = grid.fit(x_train, y_train) #callbacks=[tbCallBack]\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "for test_mean, test_stdev, train_mean, train_stdev, param in zip(\n",
        "        grid_result.cv_results_['mean_test_score'],\n",
        "        grid_result.cv_results_['std_test_score'],\n",
        "        grid_result.cv_results_['mean_train_score'],\n",
        "        grid_result.cv_results_['std_train_score'],\n",
        "        grid_result.cv_results_['params']):\n",
        "    print(\"Train: %f (%f) // Test : %f (%f) with: %r\" % (train_mean, train_stdev, test_mean, test_stdev, param))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.1min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  4.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "920/920 [==============================] - 0s 184us/step - loss: 0.6593 - accuracy: 0.5826 - mae: 0.4692\n",
            "Epoch 2/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.6290 - accuracy: 0.6435 - mae: 0.4452\n",
            "Epoch 3/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.6079 - accuracy: 0.6761 - mae: 0.4240\n",
            "Epoch 4/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5976 - accuracy: 0.7065 - mae: 0.4135\n",
            "Epoch 5/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5791 - accuracy: 0.7065 - mae: 0.4021\n",
            "Epoch 6/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.5696 - accuracy: 0.7098 - mae: 0.3953\n",
            "Epoch 7/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5694 - accuracy: 0.7239 - mae: 0.3836\n",
            "Epoch 8/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5522 - accuracy: 0.7228 - mae: 0.3823\n",
            "Epoch 9/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5566 - accuracy: 0.7174 - mae: 0.3769\n",
            "Epoch 10/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5823 - accuracy: 0.7293 - mae: 0.3762\n",
            "Epoch 11/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5645 - accuracy: 0.7272 - mae: 0.3791\n",
            "Epoch 12/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5532 - accuracy: 0.7348 - mae: 0.3792\n",
            "Epoch 13/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5344 - accuracy: 0.7283 - mae: 0.3679\n",
            "Epoch 14/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5266 - accuracy: 0.7424 - mae: 0.3566\n",
            "Epoch 15/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5242 - accuracy: 0.7424 - mae: 0.3522\n",
            "Epoch 16/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5132 - accuracy: 0.7478 - mae: 0.3503\n",
            "Epoch 17/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5287 - accuracy: 0.7413 - mae: 0.3498\n",
            "Epoch 18/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5093 - accuracy: 0.7565 - mae: 0.3427\n",
            "Epoch 19/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5040 - accuracy: 0.7641 - mae: 0.3346\n",
            "Epoch 20/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5132 - accuracy: 0.7522 - mae: 0.3439\n",
            "Epoch 21/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4942 - accuracy: 0.7663 - mae: 0.3285\n",
            "Epoch 22/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4923 - accuracy: 0.7576 - mae: 0.3345\n",
            "Epoch 23/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5106 - accuracy: 0.7554 - mae: 0.3354\n",
            "Epoch 24/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4854 - accuracy: 0.7641 - mae: 0.3239\n",
            "Epoch 25/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.5613 - accuracy: 0.7326 - mae: 0.3553\n",
            "Epoch 26/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.5391 - accuracy: 0.7217 - mae: 0.3746\n",
            "Epoch 27/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5130 - accuracy: 0.7402 - mae: 0.3462\n",
            "Epoch 28/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5166 - accuracy: 0.7380 - mae: 0.3411\n",
            "Epoch 29/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.5038 - accuracy: 0.7413 - mae: 0.3352\n",
            "Epoch 30/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.5020 - accuracy: 0.7587 - mae: 0.3339\n",
            "Epoch 31/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.4936 - accuracy: 0.7620 - mae: 0.3273\n",
            "Epoch 32/100\n",
            "920/920 [==============================] - 0s 84us/step - loss: 0.5037 - accuracy: 0.7511 - mae: 0.3333\n",
            "Epoch 33/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.4772 - accuracy: 0.7620 - mae: 0.3213\n",
            "Epoch 34/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4773 - accuracy: 0.7750 - mae: 0.3183\n",
            "Epoch 35/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4896 - accuracy: 0.7489 - mae: 0.3233\n",
            "Epoch 36/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4839 - accuracy: 0.7565 - mae: 0.3216\n",
            "Epoch 37/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4714 - accuracy: 0.7598 - mae: 0.3173\n",
            "Epoch 38/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4900 - accuracy: 0.7696 - mae: 0.3100\n",
            "Epoch 39/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4759 - accuracy: 0.7685 - mae: 0.3213\n",
            "Epoch 40/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4669 - accuracy: 0.7707 - mae: 0.3079\n",
            "Epoch 41/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4664 - accuracy: 0.7641 - mae: 0.3109\n",
            "Epoch 42/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4662 - accuracy: 0.7761 - mae: 0.3074\n",
            "Epoch 43/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4550 - accuracy: 0.7750 - mae: 0.3056\n",
            "Epoch 44/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4465 - accuracy: 0.7772 - mae: 0.3023\n",
            "Epoch 45/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4711 - accuracy: 0.7826 - mae: 0.2969\n",
            "Epoch 46/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4601 - accuracy: 0.7924 - mae: 0.3068\n",
            "Epoch 47/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4512 - accuracy: 0.7826 - mae: 0.3035\n",
            "Epoch 48/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4529 - accuracy: 0.7793 - mae: 0.3010\n",
            "Epoch 49/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4673 - accuracy: 0.7761 - mae: 0.3054\n",
            "Epoch 50/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4454 - accuracy: 0.7880 - mae: 0.2994\n",
            "Epoch 51/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4541 - accuracy: 0.7793 - mae: 0.2947\n",
            "Epoch 52/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4361 - accuracy: 0.7826 - mae: 0.2931\n",
            "Epoch 53/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4465 - accuracy: 0.7902 - mae: 0.2916\n",
            "Epoch 54/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4419 - accuracy: 0.7859 - mae: 0.2903\n",
            "Epoch 55/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4337 - accuracy: 0.7826 - mae: 0.2897\n",
            "Epoch 56/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4562 - accuracy: 0.7772 - mae: 0.2982\n",
            "Epoch 57/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4455 - accuracy: 0.7924 - mae: 0.2934\n",
            "Epoch 58/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4341 - accuracy: 0.8022 - mae: 0.2876\n",
            "Epoch 59/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4419 - accuracy: 0.7935 - mae: 0.2880\n",
            "Epoch 60/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4374 - accuracy: 0.7859 - mae: 0.2862\n",
            "Epoch 61/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4333 - accuracy: 0.7826 - mae: 0.2861\n",
            "Epoch 62/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4474 - accuracy: 0.7837 - mae: 0.2891\n",
            "Epoch 63/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4405 - accuracy: 0.7880 - mae: 0.2883\n",
            "Epoch 64/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4321 - accuracy: 0.7848 - mae: 0.2864\n",
            "Epoch 65/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4301 - accuracy: 0.7902 - mae: 0.2851\n",
            "Epoch 66/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4451 - accuracy: 0.7728 - mae: 0.2910\n",
            "Epoch 67/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4293 - accuracy: 0.7935 - mae: 0.2811\n",
            "Epoch 68/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4261 - accuracy: 0.7913 - mae: 0.2852\n",
            "Epoch 69/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4279 - accuracy: 0.8033 - mae: 0.2780\n",
            "Epoch 70/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.4279 - accuracy: 0.8033 - mae: 0.2836\n",
            "Epoch 71/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4244 - accuracy: 0.8011 - mae: 0.2759\n",
            "Epoch 72/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4435 - accuracy: 0.7870 - mae: 0.2930\n",
            "Epoch 73/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4287 - accuracy: 0.8043 - mae: 0.2815\n",
            "Epoch 74/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4136 - accuracy: 0.8011 - mae: 0.2730\n",
            "Epoch 75/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4157 - accuracy: 0.8043 - mae: 0.2737\n",
            "Epoch 76/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4248 - accuracy: 0.7859 - mae: 0.2740\n",
            "Epoch 77/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4176 - accuracy: 0.7989 - mae: 0.2716\n",
            "Epoch 78/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4144 - accuracy: 0.8011 - mae: 0.2682\n",
            "Epoch 79/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4368 - accuracy: 0.7957 - mae: 0.2857\n",
            "Epoch 80/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4331 - accuracy: 0.7870 - mae: 0.2793\n",
            "Epoch 81/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4213 - accuracy: 0.8043 - mae: 0.2808\n",
            "Epoch 82/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4328 - accuracy: 0.8022 - mae: 0.2799\n",
            "Epoch 83/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4284 - accuracy: 0.7783 - mae: 0.2808\n",
            "Epoch 84/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4200 - accuracy: 0.8043 - mae: 0.2788\n",
            "Epoch 85/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4327 - accuracy: 0.8065 - mae: 0.2793\n",
            "Epoch 86/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4439 - accuracy: 0.7957 - mae: 0.2865\n",
            "Epoch 87/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4168 - accuracy: 0.8033 - mae: 0.2768\n",
            "Epoch 88/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4176 - accuracy: 0.8000 - mae: 0.2781\n",
            "Epoch 89/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4207 - accuracy: 0.8076 - mae: 0.2736\n",
            "Epoch 90/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4405 - accuracy: 0.7913 - mae: 0.2872\n",
            "Epoch 91/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4322 - accuracy: 0.7902 - mae: 0.2803\n",
            "Epoch 92/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4154 - accuracy: 0.8065 - mae: 0.2767\n",
            "Epoch 93/100\n",
            "920/920 [==============================] - 0s 63us/step - loss: 0.4211 - accuracy: 0.8033 - mae: 0.2742\n",
            "Epoch 94/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4174 - accuracy: 0.8087 - mae: 0.2709\n",
            "Epoch 95/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4106 - accuracy: 0.8109 - mae: 0.2695\n",
            "Epoch 96/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.4211 - accuracy: 0.8011 - mae: 0.2709\n",
            "Epoch 97/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4085 - accuracy: 0.8033 - mae: 0.2713\n",
            "Epoch 98/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4303 - accuracy: 0.7957 - mae: 0.2755\n",
            "Epoch 99/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4236 - accuracy: 0.7946 - mae: 0.2780\n",
            "Epoch 100/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4283 - accuracy: 0.7978 - mae: 0.2708\n",
            "Best: 0.731253 using {'kc__batch_size': 16, 'kc__epochs': 100}\n",
            "Train: 0.735971 (0.020179) // Test : 0.698593 (0.030800) with: {'kc__batch_size': 2, 'kc__epochs': 10}\n",
            "Train: 0.746044 (0.044175) // Test : 0.698382 (0.031918) with: {'kc__batch_size': 2, 'kc__epochs': 50}\n",
            "Train: 0.769410 (0.051046) // Test : 0.697635 (0.049299) with: {'kc__batch_size': 2, 'kc__epochs': 100}\n",
            "Train: 0.723334 (0.015042) // Test : 0.697414 (0.037293) with: {'kc__batch_size': 16, 'kc__epochs': 10}\n",
            "Train: 0.795825 (0.018709) // Test : 0.725930 (0.028007) with: {'kc__batch_size': 16, 'kc__epochs': 50}\n",
            "Train: 0.803448 (0.015822) // Test : 0.731253 (0.032059) with: {'kc__batch_size': 16, 'kc__epochs': 100}\n",
            "Train: 0.720009 (0.009599) // Test : 0.692056 (0.037600) with: {'kc__batch_size': 32, 'kc__epochs': 10}\n",
            "Train: 0.789829 (0.009682) // Test : 0.724196 (0.026614) with: {'kc__batch_size': 32, 'kc__epochs': 50}\n",
            "Train: 0.804797 (0.013194) // Test : 0.709600 (0.043017) with: {'kc__batch_size': 32, 'kc__epochs': 100}\n",
            "Train: 0.716426 (0.015905) // Test : 0.682980 (0.025636) with: {'kc__batch_size': 46, 'kc__epochs': 10}\n",
            "Train: 0.781621 (0.016265) // Test : 0.726038 (0.027531) with: {'kc__batch_size': 46, 'kc__epochs': 50}\n",
            "Train: 0.808130 (0.018183) // Test : 0.719480 (0.038714) with: {'kc__batch_size': 46, 'kc__epochs': 100}\n",
            "Train: 0.706510 (0.020400) // Test : 0.684570 (0.038288) with: {'kc__batch_size': 64, 'kc__epochs': 10}\n",
            "Train: 0.797007 (0.013652) // Test : 0.719302 (0.039887) with: {'kc__batch_size': 64, 'kc__epochs': 50}\n",
            "Train: 0.807617 (0.020082) // Test : 0.724969 (0.042666) with: {'kc__batch_size': 64, 'kc__epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjP2YKEG1HFd",
        "colab_type": "text"
      },
      "source": [
        "### Tuning no of neurons in first and second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDMIy87i1GNa",
        "colab_type": "code",
        "outputId": "945b77ad-2342-4f5e-9664-b2e6e0e28940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model_1(neuron1 = 8 , neuron2= 4):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 19,kernel_initializer = 'uniform' ,activation = 'relu'))\n",
        "    \n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer =  'uniform' ,activation = 'relu'))\n",
        "    \n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    opt = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy','mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "kears_estimator = KerasClassifier(build_fn=create_model_1, verbose=1, batch_size=16 , epochs = 100)\n",
        "\n",
        "cnf = Pipeline([ \n",
        "                # ('feature_selection', SelectFromModel(LinearSVC(C=0.07, penalty=\"l1\", dual=False, max_iter = 1000))),\n",
        "                     \n",
        "                       (\"kc\", kears_estimator),\n",
        "                ])\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid_1 = {\n",
        "    # 'kc__dense_layer_sizes' : [ (12), (12,4),(8),(8,4),(10),(10,4) ],\n",
        "    # 'kc__epochs': [10,50,100, ],\n",
        "    # 'kc__dense_nparams': [12, 8, 10],\n",
        "    # 'kc__init': [ 'uniform', 'zeros', 'normal', ],\n",
        "    # 'kc__activation' : ['softmax','relu','tanh','linear',], \n",
        "    # 'kc__batch_size':[2, 16, 32, 64],\n",
        "    # 'kc__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
        "    # 'kc__dropout': [ 0.3, 0.25, 0.2,0.05, 0.1, 0],\n",
        "    # 'kc__learning_rate':[0.1,0.01,0.001,0.005],\n",
        "    'kc__neuron1' : [12,10,8],\n",
        "    'kc__neuron2' : [2,3,4,6],\n",
        "}\n",
        "\n",
        "kfold_splits = 5\n",
        "grid = GridSearchCV(estimator=cnf,  \n",
        "                    n_jobs=-1, \n",
        "                    verbose=10,\n",
        "                    return_train_score=True,\n",
        "                    cv=kfold_splits,  \n",
        "                    param_grid=param_grid_1,\n",
        "                    scoring = 'f1',\n",
        "                  )\n",
        "\n",
        "\n",
        "grid_result = grid.fit(x_train, y_train) #callbacks=[tbCallBack]\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "for test_mean, test_stdev, train_mean, train_stdev, param in zip(\n",
        "        grid_result.cv_results_['mean_test_score'],\n",
        "        grid_result.cv_results_['std_test_score'],\n",
        "        grid_result.cv_results_['mean_train_score'],\n",
        "        grid_result.cv_results_['std_train_score'],\n",
        "        grid_result.cv_results_['params']):\n",
        "    print(\"Train: %f (%f) // Test : %f (%f) with: %r\" % (train_mean, train_stdev, test_mean, test_stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   18.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   40.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   56.7s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "920/920 [==============================] - 0s 190us/step - loss: 0.6638 - accuracy: 0.5304 - mae: 0.4804\n",
            "Epoch 2/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.6489 - accuracy: 0.5880 - mae: 0.4653\n",
            "Epoch 3/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.6428 - accuracy: 0.6043 - mae: 0.4611\n",
            "Epoch 4/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.6368 - accuracy: 0.6120 - mae: 0.4566\n",
            "Epoch 5/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.6303 - accuracy: 0.6283 - mae: 0.4526\n",
            "Epoch 6/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.6229 - accuracy: 0.6435 - mae: 0.4459\n",
            "Epoch 7/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.6156 - accuracy: 0.6467 - mae: 0.4405\n",
            "Epoch 8/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.6090 - accuracy: 0.6630 - mae: 0.4355\n",
            "Epoch 9/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.6034 - accuracy: 0.6793 - mae: 0.4319\n",
            "Epoch 10/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5983 - accuracy: 0.6826 - mae: 0.4247\n",
            "Epoch 11/100\n",
            "920/920 [==============================] - 0s 65us/step - loss: 0.5867 - accuracy: 0.7054 - mae: 0.4211\n",
            "Epoch 12/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5793 - accuracy: 0.7152 - mae: 0.4113\n",
            "Epoch 13/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5766 - accuracy: 0.7163 - mae: 0.4106\n",
            "Epoch 14/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5638 - accuracy: 0.7315 - mae: 0.4023\n",
            "Epoch 15/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5613 - accuracy: 0.7261 - mae: 0.4007\n",
            "Epoch 16/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5561 - accuracy: 0.7283 - mae: 0.3967\n",
            "Epoch 17/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5553 - accuracy: 0.7207 - mae: 0.3889\n",
            "Epoch 18/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5462 - accuracy: 0.7359 - mae: 0.3862\n",
            "Epoch 19/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5440 - accuracy: 0.7370 - mae: 0.3839\n",
            "Epoch 20/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5387 - accuracy: 0.7326 - mae: 0.3818\n",
            "Epoch 21/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5322 - accuracy: 0.7261 - mae: 0.3760\n",
            "Epoch 22/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5294 - accuracy: 0.7424 - mae: 0.3722\n",
            "Epoch 23/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5263 - accuracy: 0.7380 - mae: 0.3729\n",
            "Epoch 24/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5241 - accuracy: 0.7402 - mae: 0.3680\n",
            "Epoch 25/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5195 - accuracy: 0.7435 - mae: 0.3643\n",
            "Epoch 26/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5174 - accuracy: 0.7391 - mae: 0.3628\n",
            "Epoch 27/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.5182 - accuracy: 0.7500 - mae: 0.3626\n",
            "Epoch 28/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5129 - accuracy: 0.7489 - mae: 0.3595\n",
            "Epoch 29/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5139 - accuracy: 0.7446 - mae: 0.3576\n",
            "Epoch 30/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5184 - accuracy: 0.7391 - mae: 0.3567\n",
            "Epoch 31/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5168 - accuracy: 0.7402 - mae: 0.3538\n",
            "Epoch 32/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5093 - accuracy: 0.7489 - mae: 0.3548\n",
            "Epoch 33/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5116 - accuracy: 0.7467 - mae: 0.3525\n",
            "Epoch 34/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5004 - accuracy: 0.7511 - mae: 0.3489\n",
            "Epoch 35/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.5036 - accuracy: 0.7500 - mae: 0.3475\n",
            "Epoch 36/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5036 - accuracy: 0.7511 - mae: 0.3466\n",
            "Epoch 37/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5197 - accuracy: 0.7424 - mae: 0.3502\n",
            "Epoch 38/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5001 - accuracy: 0.7511 - mae: 0.3447\n",
            "Epoch 39/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4992 - accuracy: 0.7446 - mae: 0.3449\n",
            "Epoch 40/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4985 - accuracy: 0.7478 - mae: 0.3441\n",
            "Epoch 41/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4962 - accuracy: 0.7543 - mae: 0.3410\n",
            "Epoch 42/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4916 - accuracy: 0.7533 - mae: 0.3418\n",
            "Epoch 43/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4902 - accuracy: 0.7478 - mae: 0.3375\n",
            "Epoch 44/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5863 - accuracy: 0.7543 - mae: 0.3434\n",
            "Epoch 45/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5611 - accuracy: 0.7402 - mae: 0.3421\n",
            "Epoch 46/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5267 - accuracy: 0.7533 - mae: 0.3411\n",
            "Epoch 47/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5118 - accuracy: 0.7511 - mae: 0.3415\n",
            "Epoch 48/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4965 - accuracy: 0.7554 - mae: 0.3408\n",
            "Epoch 49/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4908 - accuracy: 0.7576 - mae: 0.3396\n",
            "Epoch 50/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4871 - accuracy: 0.7522 - mae: 0.3380\n",
            "Epoch 51/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4873 - accuracy: 0.7587 - mae: 0.3374\n",
            "Epoch 52/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4856 - accuracy: 0.7620 - mae: 0.3383\n",
            "Epoch 53/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4838 - accuracy: 0.7543 - mae: 0.3341\n",
            "Epoch 54/100\n",
            "920/920 [==============================] - 0s 84us/step - loss: 0.4833 - accuracy: 0.7522 - mae: 0.3350\n",
            "Epoch 55/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4810 - accuracy: 0.7565 - mae: 0.3317\n",
            "Epoch 56/100\n",
            "920/920 [==============================] - 0s 89us/step - loss: 0.4777 - accuracy: 0.7620 - mae: 0.3317\n",
            "Epoch 57/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4831 - accuracy: 0.7587 - mae: 0.3322\n",
            "Epoch 58/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4784 - accuracy: 0.7543 - mae: 0.3297\n",
            "Epoch 59/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.4757 - accuracy: 0.7641 - mae: 0.3287\n",
            "Epoch 60/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4727 - accuracy: 0.7587 - mae: 0.3278\n",
            "Epoch 61/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.4834 - accuracy: 0.7533 - mae: 0.3289\n",
            "Epoch 62/100\n",
            "920/920 [==============================] - 0s 86us/step - loss: 0.4739 - accuracy: 0.7522 - mae: 0.3266\n",
            "Epoch 63/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4748 - accuracy: 0.7620 - mae: 0.3263\n",
            "Epoch 64/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4756 - accuracy: 0.7587 - mae: 0.3274\n",
            "Epoch 65/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4725 - accuracy: 0.7565 - mae: 0.3260\n",
            "Epoch 66/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4701 - accuracy: 0.7641 - mae: 0.3245\n",
            "Epoch 67/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4730 - accuracy: 0.7609 - mae: 0.3237\n",
            "Epoch 68/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4713 - accuracy: 0.7663 - mae: 0.3225\n",
            "Epoch 69/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4678 - accuracy: 0.7685 - mae: 0.3223\n",
            "Epoch 70/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4697 - accuracy: 0.7674 - mae: 0.3205\n",
            "Epoch 71/100\n",
            "920/920 [==============================] - 0s 86us/step - loss: 0.4680 - accuracy: 0.7652 - mae: 0.3209\n",
            "Epoch 72/100\n",
            "920/920 [==============================] - 0s 85us/step - loss: 0.4732 - accuracy: 0.7620 - mae: 0.3207\n",
            "Epoch 73/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4677 - accuracy: 0.7641 - mae: 0.3213\n",
            "Epoch 74/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4650 - accuracy: 0.7728 - mae: 0.3186\n",
            "Epoch 75/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4630 - accuracy: 0.7696 - mae: 0.3168\n",
            "Epoch 76/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4639 - accuracy: 0.7707 - mae: 0.3173\n",
            "Epoch 77/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4604 - accuracy: 0.7804 - mae: 0.3148\n",
            "Epoch 78/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4617 - accuracy: 0.7739 - mae: 0.3163\n",
            "Epoch 79/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4619 - accuracy: 0.7772 - mae: 0.3161\n",
            "Epoch 80/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4605 - accuracy: 0.7750 - mae: 0.3159\n",
            "Epoch 81/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4586 - accuracy: 0.7728 - mae: 0.3118\n",
            "Epoch 82/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.4579 - accuracy: 0.7804 - mae: 0.3139\n",
            "Epoch 83/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4573 - accuracy: 0.7783 - mae: 0.3116\n",
            "Epoch 84/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4583 - accuracy: 0.7696 - mae: 0.3133\n",
            "Epoch 85/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4583 - accuracy: 0.7793 - mae: 0.3119\n",
            "Epoch 86/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4613 - accuracy: 0.7696 - mae: 0.3152\n",
            "Epoch 87/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5124 - accuracy: 0.7739 - mae: 0.3146\n",
            "Epoch 88/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5424 - accuracy: 0.7783 - mae: 0.3168\n",
            "Epoch 89/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5100 - accuracy: 0.7674 - mae: 0.3193\n",
            "Epoch 90/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4863 - accuracy: 0.7815 - mae: 0.3193\n",
            "Epoch 91/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4702 - accuracy: 0.7848 - mae: 0.3176\n",
            "Epoch 92/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4630 - accuracy: 0.7804 - mae: 0.3175\n",
            "Epoch 93/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4550 - accuracy: 0.7793 - mae: 0.3146\n",
            "Epoch 94/100\n",
            "920/920 [==============================] - 0s 65us/step - loss: 0.4526 - accuracy: 0.7783 - mae: 0.3123\n",
            "Epoch 95/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4506 - accuracy: 0.7880 - mae: 0.3091\n",
            "Epoch 96/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4497 - accuracy: 0.7783 - mae: 0.3093\n",
            "Epoch 97/100\n",
            "920/920 [==============================] - 0s 65us/step - loss: 0.4490 - accuracy: 0.7902 - mae: 0.3089\n",
            "Epoch 98/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4668 - accuracy: 0.7783 - mae: 0.3098\n",
            "Epoch 99/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4534 - accuracy: 0.7793 - mae: 0.3093\n",
            "Epoch 100/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4464 - accuracy: 0.7913 - mae: 0.3062\n",
            "Best: 0.738154 using {'kc__neuron1': 12, 'kc__neuron2': 4}\n",
            "Train: 0.787593 (0.010418) // Test : 0.722575 (0.045190) with: {'kc__neuron1': 12, 'kc__neuron2': 2}\n",
            "Train: 0.783505 (0.015379) // Test : 0.735401 (0.033297) with: {'kc__neuron1': 12, 'kc__neuron2': 3}\n",
            "Train: 0.785568 (0.012228) // Test : 0.738154 (0.024026) with: {'kc__neuron1': 12, 'kc__neuron2': 4}\n",
            "Train: 0.784820 (0.012919) // Test : 0.721939 (0.025494) with: {'kc__neuron1': 12, 'kc__neuron2': 6}\n",
            "Train: 0.770133 (0.013363) // Test : 0.702323 (0.038965) with: {'kc__neuron1': 10, 'kc__neuron2': 2}\n",
            "Train: 0.769778 (0.028723) // Test : 0.717656 (0.020838) with: {'kc__neuron1': 10, 'kc__neuron2': 3}\n",
            "Train: 0.781174 (0.016520) // Test : 0.720585 (0.042151) with: {'kc__neuron1': 10, 'kc__neuron2': 4}\n",
            "Train: 0.765849 (0.046997) // Test : 0.705805 (0.049757) with: {'kc__neuron1': 10, 'kc__neuron2': 6}\n",
            "Train: 0.765581 (0.019032) // Test : 0.716911 (0.022530) with: {'kc__neuron1': 8, 'kc__neuron2': 2}\n",
            "Train: 0.760639 (0.024572) // Test : 0.720300 (0.027840) with: {'kc__neuron1': 8, 'kc__neuron2': 3}\n",
            "Train: 0.772562 (0.017639) // Test : 0.734218 (0.022844) with: {'kc__neuron1': 8, 'kc__neuron2': 4}\n",
            "Train: 0.777696 (0.010618) // Test : 0.722117 (0.034095) with: {'kc__neuron1': 8, 'kc__neuron2': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5LeMQ_FsmnO",
        "colab_type": "text"
      },
      "source": [
        "### Tuning learning rate and dropout rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsQzyNETslof",
        "colab_type": "code",
        "outputId": "c4c079c9-c757-479d-bea8-d20d21610c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "def create_model_1(dropout=0.1 , learning_rate=0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12,input_dim = 19,kernel_initializer = 'uniform',activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(4,input_dim = 12,kernel_initializer =  'uniform',activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    opt = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy','mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "kears_estimator = KerasClassifier(build_fn=create_model_1, verbose=1, batch_size=16 , epochs = 100)\n",
        "\n",
        "cnf = Pipeline([ \n",
        "                # ('feature_selection', SelectFromModel(LinearSVC(C=0.07, penalty=\"l1\", dual=False, max_iter = 1000))),\n",
        "                     \n",
        "                       (\"kc\", kears_estimator),\n",
        "                ])\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid_1 = {\n",
        "    # 'kc__dense_layer_sizes' : [ (12), (12,4),(8),(8,4),(10),(10,4) ],\n",
        "    # 'kc__epochs': [10,50,100, ],\n",
        "    # 'kc__dense_nparams': [12, 8, 10],\n",
        "    # 'kc__init': [ 'uniform', 'zeros', 'normal', ], \n",
        "    # 'kc__batch_size':[2, 16, 32, 64],\n",
        "    # 'kc__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
        "    'kc__dropout': [ 0.25, 0.2,0.15, 0.1,0.05, 0],\n",
        "    'kc__learning_rate':[0.01,0.001,0.005,0.004],\n",
        "}\n",
        "\n",
        "kfold_splits = 5\n",
        "grid = GridSearchCV(estimator=cnf,  \n",
        "                    n_jobs=-1, \n",
        "                    verbose=10,\n",
        "                    return_train_score=True,\n",
        "                    cv=kfold_splits,  \n",
        "                    param_grid=param_grid_1,\n",
        "                    scoring = 'f1',\n",
        "                  )\n",
        "\n",
        "\n",
        "grid_result = grid.fit(x_train, y_train) #callbacks=[tbCallBack]\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "for test_mean, test_stdev, train_mean, train_stdev, param in zip(\n",
        "        grid_result.cv_results_['mean_test_score'],\n",
        "        grid_result.cv_results_['std_test_score'],\n",
        "        grid_result.cv_results_['mean_train_score'],\n",
        "        grid_result.cv_results_['std_train_score'],\n",
        "        grid_result.cv_results_['params']):\n",
        "    print(\"Train: %f (%f) // Test : %f (%f) with: %r\" % (train_mean, train_stdev, test_mean, test_stdev, param))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   41.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   58.7s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.0min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  8.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "920/920 [==============================] - 0s 161us/step - loss: 0.6520 - accuracy: 0.5609 - mae: 0.4647\n",
            "Epoch 2/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.6369 - accuracy: 0.6380 - mae: 0.4552\n",
            "Epoch 3/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.6296 - accuracy: 0.6359 - mae: 0.4463\n",
            "Epoch 4/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.6149 - accuracy: 0.6685 - mae: 0.4395\n",
            "Epoch 5/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.6015 - accuracy: 0.6685 - mae: 0.4253\n",
            "Epoch 6/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5865 - accuracy: 0.6902 - mae: 0.4182\n",
            "Epoch 7/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.5847 - accuracy: 0.6967 - mae: 0.4134\n",
            "Epoch 8/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5847 - accuracy: 0.6880 - mae: 0.4118\n",
            "Epoch 9/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5859 - accuracy: 0.7098 - mae: 0.4070\n",
            "Epoch 10/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5720 - accuracy: 0.7293 - mae: 0.3972\n",
            "Epoch 11/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5803 - accuracy: 0.7217 - mae: 0.3966\n",
            "Epoch 12/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5568 - accuracy: 0.7315 - mae: 0.3900\n",
            "Epoch 13/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5626 - accuracy: 0.7217 - mae: 0.3900\n",
            "Epoch 14/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5536 - accuracy: 0.7239 - mae: 0.3865\n",
            "Epoch 15/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.5483 - accuracy: 0.7359 - mae: 0.3832\n",
            "Epoch 16/100\n",
            "920/920 [==============================] - 0s 85us/step - loss: 0.5436 - accuracy: 0.7359 - mae: 0.3751\n",
            "Epoch 17/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.5366 - accuracy: 0.7370 - mae: 0.3716\n",
            "Epoch 18/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.5413 - accuracy: 0.7315 - mae: 0.3733\n",
            "Epoch 19/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.5418 - accuracy: 0.7467 - mae: 0.3706\n",
            "Epoch 20/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5353 - accuracy: 0.7446 - mae: 0.3653\n",
            "Epoch 21/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5303 - accuracy: 0.7424 - mae: 0.3632\n",
            "Epoch 22/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5321 - accuracy: 0.7435 - mae: 0.3660\n",
            "Epoch 23/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.5299 - accuracy: 0.7511 - mae: 0.3583\n",
            "Epoch 24/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5184 - accuracy: 0.7478 - mae: 0.3591\n",
            "Epoch 25/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5360 - accuracy: 0.7348 - mae: 0.3592\n",
            "Epoch 26/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5255 - accuracy: 0.7533 - mae: 0.3597\n",
            "Epoch 27/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5158 - accuracy: 0.7587 - mae: 0.3550\n",
            "Epoch 28/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5402 - accuracy: 0.7359 - mae: 0.3611\n",
            "Epoch 29/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5120 - accuracy: 0.7674 - mae: 0.3506\n",
            "Epoch 30/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5140 - accuracy: 0.7489 - mae: 0.3519\n",
            "Epoch 31/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5041 - accuracy: 0.7641 - mae: 0.3456\n",
            "Epoch 32/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.5073 - accuracy: 0.7576 - mae: 0.3434\n",
            "Epoch 33/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5125 - accuracy: 0.7478 - mae: 0.3480\n",
            "Epoch 34/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4993 - accuracy: 0.7543 - mae: 0.3460\n",
            "Epoch 35/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5084 - accuracy: 0.7620 - mae: 0.3436\n",
            "Epoch 36/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4967 - accuracy: 0.7641 - mae: 0.3373\n",
            "Epoch 37/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5157 - accuracy: 0.7380 - mae: 0.3479\n",
            "Epoch 38/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4908 - accuracy: 0.7685 - mae: 0.3357\n",
            "Epoch 39/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.5050 - accuracy: 0.7511 - mae: 0.3389\n",
            "Epoch 40/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4968 - accuracy: 0.7652 - mae: 0.3406\n",
            "Epoch 41/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4910 - accuracy: 0.7717 - mae: 0.3344\n",
            "Epoch 42/100\n",
            "920/920 [==============================] - 0s 84us/step - loss: 0.4948 - accuracy: 0.7620 - mae: 0.3380\n",
            "Epoch 43/100\n",
            "920/920 [==============================] - 0s 93us/step - loss: 0.4834 - accuracy: 0.7609 - mae: 0.3290\n",
            "Epoch 44/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4830 - accuracy: 0.7739 - mae: 0.3318\n",
            "Epoch 45/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4746 - accuracy: 0.7750 - mae: 0.3221\n",
            "Epoch 46/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4791 - accuracy: 0.7652 - mae: 0.3250\n",
            "Epoch 47/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4740 - accuracy: 0.7739 - mae: 0.3225\n",
            "Epoch 48/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.4750 - accuracy: 0.7663 - mae: 0.3221\n",
            "Epoch 49/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4705 - accuracy: 0.7717 - mae: 0.3215\n",
            "Epoch 50/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4814 - accuracy: 0.7674 - mae: 0.3250\n",
            "Epoch 51/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4802 - accuracy: 0.7750 - mae: 0.3211\n",
            "Epoch 52/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4780 - accuracy: 0.7685 - mae: 0.3189\n",
            "Epoch 53/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4699 - accuracy: 0.7739 - mae: 0.3155\n",
            "Epoch 54/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4734 - accuracy: 0.7826 - mae: 0.3214\n",
            "Epoch 55/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.4718 - accuracy: 0.7663 - mae: 0.3168\n",
            "Epoch 56/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4647 - accuracy: 0.7685 - mae: 0.3105\n",
            "Epoch 57/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4689 - accuracy: 0.7641 - mae: 0.3146\n",
            "Epoch 58/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4621 - accuracy: 0.7826 - mae: 0.3112\n",
            "Epoch 59/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4633 - accuracy: 0.7750 - mae: 0.3132\n",
            "Epoch 60/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4559 - accuracy: 0.7750 - mae: 0.3067\n",
            "Epoch 61/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.5016 - accuracy: 0.7663 - mae: 0.3239\n",
            "Epoch 62/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4737 - accuracy: 0.7685 - mae: 0.3163\n",
            "Epoch 63/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4573 - accuracy: 0.7739 - mae: 0.3082\n",
            "Epoch 64/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4590 - accuracy: 0.7815 - mae: 0.3097\n",
            "Epoch 65/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4575 - accuracy: 0.7728 - mae: 0.3088\n",
            "Epoch 66/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4521 - accuracy: 0.7761 - mae: 0.3075\n",
            "Epoch 67/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4646 - accuracy: 0.7783 - mae: 0.3088\n",
            "Epoch 68/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4586 - accuracy: 0.7815 - mae: 0.3094\n",
            "Epoch 69/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4525 - accuracy: 0.7717 - mae: 0.3021\n",
            "Epoch 70/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4493 - accuracy: 0.7750 - mae: 0.3025\n",
            "Epoch 71/100\n",
            "920/920 [==============================] - 0s 89us/step - loss: 0.4453 - accuracy: 0.7924 - mae: 0.3004\n",
            "Epoch 72/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4473 - accuracy: 0.7815 - mae: 0.3018\n",
            "Epoch 73/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4456 - accuracy: 0.7924 - mae: 0.2945\n",
            "Epoch 74/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4450 - accuracy: 0.7848 - mae: 0.2981\n",
            "Epoch 75/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4483 - accuracy: 0.7761 - mae: 0.3005\n",
            "Epoch 76/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4523 - accuracy: 0.7837 - mae: 0.3038\n",
            "Epoch 77/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4360 - accuracy: 0.7935 - mae: 0.2942\n",
            "Epoch 78/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4392 - accuracy: 0.7891 - mae: 0.2938\n",
            "Epoch 79/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4535 - accuracy: 0.7848 - mae: 0.2975\n",
            "Epoch 80/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4486 - accuracy: 0.7913 - mae: 0.2954\n",
            "Epoch 81/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4621 - accuracy: 0.7750 - mae: 0.3034\n",
            "Epoch 82/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4510 - accuracy: 0.7783 - mae: 0.2981\n",
            "Epoch 83/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4529 - accuracy: 0.7772 - mae: 0.3030\n",
            "Epoch 84/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4434 - accuracy: 0.7848 - mae: 0.2990\n",
            "Epoch 85/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4318 - accuracy: 0.8022 - mae: 0.2882\n",
            "Epoch 86/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4357 - accuracy: 0.7946 - mae: 0.2911\n",
            "Epoch 87/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4341 - accuracy: 0.7913 - mae: 0.2891\n",
            "Epoch 88/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4357 - accuracy: 0.7957 - mae: 0.2900\n",
            "Epoch 89/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4312 - accuracy: 0.7859 - mae: 0.2899\n",
            "Epoch 90/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4316 - accuracy: 0.7902 - mae: 0.2879\n",
            "Epoch 91/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4369 - accuracy: 0.7859 - mae: 0.2879\n",
            "Epoch 92/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4560 - accuracy: 0.7750 - mae: 0.2976\n",
            "Epoch 93/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4290 - accuracy: 0.7935 - mae: 0.2892\n",
            "Epoch 94/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4273 - accuracy: 0.7902 - mae: 0.2850\n",
            "Epoch 95/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4379 - accuracy: 0.7880 - mae: 0.2886\n",
            "Epoch 96/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4298 - accuracy: 0.7946 - mae: 0.2848\n",
            "Epoch 97/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4196 - accuracy: 0.8022 - mae: 0.2806\n",
            "Epoch 98/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.4302 - accuracy: 0.7957 - mae: 0.2849\n",
            "Epoch 99/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4371 - accuracy: 0.7848 - mae: 0.2875\n",
            "Epoch 100/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4287 - accuracy: 0.8043 - mae: 0.2820\n",
            "Best: 0.749355 using {'kc__dropout': 0, 'kc__learning_rate': 0.005}\n",
            "Train: 0.765844 (0.028952) // Test : 0.723612 (0.046512) with: {'kc__dropout': 0.25, 'kc__learning_rate': 0.01}\n",
            "Train: 0.758307 (0.020658) // Test : 0.709313 (0.042626) with: {'kc__dropout': 0.25, 'kc__learning_rate': 0.001}\n",
            "Train: 0.789292 (0.023156) // Test : 0.705629 (0.033223) with: {'kc__dropout': 0.25, 'kc__learning_rate': 0.005}\n",
            "Train: 0.784587 (0.022937) // Test : 0.699432 (0.037099) with: {'kc__dropout': 0.25, 'kc__learning_rate': 0.004}\n",
            "Train: 0.778209 (0.030264) // Test : 0.694897 (0.018946) with: {'kc__dropout': 0.2, 'kc__learning_rate': 0.01}\n",
            "Train: 0.768545 (0.014630) // Test : 0.714435 (0.037524) with: {'kc__dropout': 0.2, 'kc__learning_rate': 0.001}\n",
            "Train: 0.782501 (0.027480) // Test : 0.702628 (0.036965) with: {'kc__dropout': 0.2, 'kc__learning_rate': 0.005}\n",
            "Train: 0.780949 (0.007678) // Test : 0.717762 (0.044048) with: {'kc__dropout': 0.2, 'kc__learning_rate': 0.004}\n",
            "Train: 0.811691 (0.020232) // Test : 0.719870 (0.036100) with: {'kc__dropout': 0.15, 'kc__learning_rate': 0.01}\n",
            "Train: 0.775133 (0.012538) // Test : 0.724659 (0.042536) with: {'kc__dropout': 0.15, 'kc__learning_rate': 0.001}\n",
            "Train: 0.791432 (0.011063) // Test : 0.690777 (0.022592) with: {'kc__dropout': 0.15, 'kc__learning_rate': 0.005}\n",
            "Train: 0.795652 (0.022448) // Test : 0.726635 (0.024043) with: {'kc__dropout': 0.15, 'kc__learning_rate': 0.004}\n",
            "Train: 0.808556 (0.025957) // Test : 0.709985 (0.044793) with: {'kc__dropout': 0.1, 'kc__learning_rate': 0.01}\n",
            "Train: 0.776770 (0.013643) // Test : 0.729605 (0.030470) with: {'kc__dropout': 0.1, 'kc__learning_rate': 0.001}\n",
            "Train: 0.808319 (0.011839) // Test : 0.703699 (0.023345) with: {'kc__dropout': 0.1, 'kc__learning_rate': 0.005}\n",
            "Train: 0.807928 (0.014316) // Test : 0.722757 (0.036232) with: {'kc__dropout': 0.1, 'kc__learning_rate': 0.004}\n",
            "Train: 0.828061 (0.019969) // Test : 0.709206 (0.021130) with: {'kc__dropout': 0.05, 'kc__learning_rate': 0.01}\n",
            "Train: 0.779107 (0.019082) // Test : 0.721394 (0.046063) with: {'kc__dropout': 0.05, 'kc__learning_rate': 0.001}\n",
            "Train: 0.793078 (0.054409) // Test : 0.718505 (0.013491) with: {'kc__dropout': 0.05, 'kc__learning_rate': 0.005}\n",
            "Train: 0.810230 (0.017521) // Test : 0.717628 (0.039007) with: {'kc__dropout': 0.05, 'kc__learning_rate': 0.004}\n",
            "Train: 0.840903 (0.019882) // Test : 0.699652 (0.031676) with: {'kc__dropout': 0, 'kc__learning_rate': 0.01}\n",
            "Train: 0.783604 (0.016651) // Test : 0.727835 (0.026335) with: {'kc__dropout': 0, 'kc__learning_rate': 0.001}\n",
            "Train: 0.818479 (0.010040) // Test : 0.749355 (0.032669) with: {'kc__dropout': 0, 'kc__learning_rate': 0.005}\n",
            "Train: 0.819118 (0.028350) // Test : 0.711089 (0.037708) with: {'kc__dropout': 0, 'kc__learning_rate': 0.004}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZtmRiTZySPW",
        "colab_type": "text"
      },
      "source": [
        "### Tuning Activation function and kernel initializer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5wLH5wVyRsv",
        "colab_type": "code",
        "outputId": "e8d9d0cc-62c1-453a-86a6-1edb2da48d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "def create_model_1(init='uniform',activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12,input_dim = 19,kernel_initializer = init ,activation = activation))\n",
        "    # model.add(Dropout(0.05))\n",
        "    model.add(Dense(4,input_dim = 12,kernel_initializer =  init ,activation = activation))\n",
        "    # model.add(Dropout(0.05))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    opt = Adam(lr = 0.005)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy','mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "kears_estimator = KerasClassifier(build_fn=create_model_1, verbose=1, batch_size=16 , epochs = 100)\n",
        "\n",
        "cnf = Pipeline([ \n",
        "                # ('feature_selection', SelectFromModel(LinearSVC(C=0.07, penalty=\"l1\", dual=False, max_iter = 1000))),\n",
        "                     \n",
        "                       (\"kc\", kears_estimator),\n",
        "                ])\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid_1 = {\n",
        "    # 'kc__dense_layer_sizes' : [ (12), (12,4),(8),(8,4),(10),(10,4) ],\n",
        "    # 'kc__epochs': [10,50,100, ],\n",
        "    # 'kc__dense_nparams': [12, 8, 10],\n",
        "    'kc__init': [ 'uniform', 'zeros', 'normal', 'glorot_uniform'],\n",
        "    'kc__activation' : ['softmax','relu','tanh','linear',], \n",
        "    # 'kc__batch_size':[2, 16, 32, 64],\n",
        "    # 'kc__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
        "    # 'kc__dropout': [ 0.3, 0.25, 0.2,0.05, 0.1, 0],\n",
        "    # 'kc__learning_rate':[0.1,0.01,0.001,0.005],\n",
        "}\n",
        "\n",
        "kfold_splits = 5\n",
        "grid = GridSearchCV(estimator=cnf,  \n",
        "                    n_jobs=-1, \n",
        "                    verbose=10,\n",
        "                    return_train_score=True,\n",
        "                    cv=kfold_splits,  \n",
        "                    param_grid=param_grid_1,\n",
        "                    scoring = 'f1',\n",
        "                  )\n",
        "\n",
        "\n",
        "grid_result = grid.fit(x_train, y_train) #callbacks=[tbCallBack]\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "for test_mean, test_stdev, train_mean, train_stdev, param in zip(\n",
        "        grid_result.cv_results_['mean_test_score'],\n",
        "        grid_result.cv_results_['std_test_score'],\n",
        "        grid_result.cv_results_['mean_train_score'],\n",
        "        grid_result.cv_results_['std_train_score'],\n",
        "        grid_result.cv_results_['params']):\n",
        "    print(\"Train: %f (%f) // Test : %f (%f) with: %r\" % (train_mean, train_stdev, test_mean, test_stdev, param))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   38.8s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   55.6s\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  5.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "920/920 [==============================] - 0s 167us/step - loss: 0.6494 - accuracy: 0.5870 - mae: 0.4629\n",
            "Epoch 2/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.6176 - accuracy: 0.6467 - mae: 0.4314\n",
            "Epoch 3/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.6090 - accuracy: 0.6696 - mae: 0.4274\n",
            "Epoch 4/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5941 - accuracy: 0.6728 - mae: 0.4148\n",
            "Epoch 5/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.5934 - accuracy: 0.6837 - mae: 0.4106\n",
            "Epoch 6/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5885 - accuracy: 0.6815 - mae: 0.4084\n",
            "Epoch 7/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5794 - accuracy: 0.6880 - mae: 0.3994\n",
            "Epoch 8/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.5732 - accuracy: 0.7065 - mae: 0.3934\n",
            "Epoch 9/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.5700 - accuracy: 0.7054 - mae: 0.3923\n",
            "Epoch 10/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5619 - accuracy: 0.7076 - mae: 0.3863\n",
            "Epoch 11/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5588 - accuracy: 0.7076 - mae: 0.3844\n",
            "Epoch 12/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5523 - accuracy: 0.7207 - mae: 0.3778\n",
            "Epoch 13/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5480 - accuracy: 0.7174 - mae: 0.3717\n",
            "Epoch 14/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.5478 - accuracy: 0.7076 - mae: 0.3688\n",
            "Epoch 15/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.5456 - accuracy: 0.7283 - mae: 0.3708\n",
            "Epoch 16/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5397 - accuracy: 0.7380 - mae: 0.3665\n",
            "Epoch 17/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5256 - accuracy: 0.7293 - mae: 0.3545\n",
            "Epoch 18/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5342 - accuracy: 0.7217 - mae: 0.3633\n",
            "Epoch 19/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.5346 - accuracy: 0.7261 - mae: 0.3589\n",
            "Epoch 20/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.5200 - accuracy: 0.7435 - mae: 0.3546\n",
            "Epoch 21/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.5256 - accuracy: 0.7413 - mae: 0.3518\n",
            "Epoch 22/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.5091 - accuracy: 0.7380 - mae: 0.3434\n",
            "Epoch 23/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.5168 - accuracy: 0.7424 - mae: 0.3466\n",
            "Epoch 24/100\n",
            "920/920 [==============================] - 0s 85us/step - loss: 0.5125 - accuracy: 0.7543 - mae: 0.3382\n",
            "Epoch 25/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.5148 - accuracy: 0.7391 - mae: 0.3444\n",
            "Epoch 26/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.5112 - accuracy: 0.7543 - mae: 0.3389\n",
            "Epoch 27/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.5092 - accuracy: 0.7533 - mae: 0.3348\n",
            "Epoch 28/100\n",
            "920/920 [==============================] - 0s 79us/step - loss: 0.5058 - accuracy: 0.7543 - mae: 0.3433\n",
            "Epoch 29/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4989 - accuracy: 0.7435 - mae: 0.3358\n",
            "Epoch 30/100\n",
            "920/920 [==============================] - 0s 78us/step - loss: 0.5198 - accuracy: 0.7380 - mae: 0.3402\n",
            "Epoch 31/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4912 - accuracy: 0.7587 - mae: 0.3374\n",
            "Epoch 32/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4925 - accuracy: 0.7674 - mae: 0.3318\n",
            "Epoch 33/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4932 - accuracy: 0.7565 - mae: 0.3297\n",
            "Epoch 34/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.4934 - accuracy: 0.7543 - mae: 0.3309\n",
            "Epoch 35/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4975 - accuracy: 0.7587 - mae: 0.3271\n",
            "Epoch 36/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4819 - accuracy: 0.7696 - mae: 0.3181\n",
            "Epoch 37/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4846 - accuracy: 0.7522 - mae: 0.3229\n",
            "Epoch 38/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4804 - accuracy: 0.7750 - mae: 0.3190\n",
            "Epoch 39/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4801 - accuracy: 0.7717 - mae: 0.3191\n",
            "Epoch 40/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4772 - accuracy: 0.7609 - mae: 0.3229\n",
            "Epoch 41/100\n",
            "920/920 [==============================] - 0s 90us/step - loss: 0.4695 - accuracy: 0.7641 - mae: 0.3146\n",
            "Epoch 42/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4872 - accuracy: 0.7685 - mae: 0.3183\n",
            "Epoch 43/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4795 - accuracy: 0.7707 - mae: 0.3177\n",
            "Epoch 44/100\n",
            "920/920 [==============================] - 0s 84us/step - loss: 0.4847 - accuracy: 0.7652 - mae: 0.3191\n",
            "Epoch 45/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.4867 - accuracy: 0.7587 - mae: 0.3230\n",
            "Epoch 46/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4687 - accuracy: 0.7685 - mae: 0.3143\n",
            "Epoch 47/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4645 - accuracy: 0.7804 - mae: 0.3111\n",
            "Epoch 48/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4743 - accuracy: 0.7609 - mae: 0.3129\n",
            "Epoch 49/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4539 - accuracy: 0.7728 - mae: 0.3074\n",
            "Epoch 50/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4475 - accuracy: 0.7837 - mae: 0.3016\n",
            "Epoch 51/100\n",
            "920/920 [==============================] - 0s 85us/step - loss: 0.4641 - accuracy: 0.7783 - mae: 0.3046\n",
            "Epoch 52/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4583 - accuracy: 0.7739 - mae: 0.3068\n",
            "Epoch 53/100\n",
            "920/920 [==============================] - 0s 86us/step - loss: 0.4517 - accuracy: 0.7728 - mae: 0.2994\n",
            "Epoch 54/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4666 - accuracy: 0.7630 - mae: 0.3065\n",
            "Epoch 55/100\n",
            "920/920 [==============================] - 0s 81us/step - loss: 0.4485 - accuracy: 0.7717 - mae: 0.2961\n",
            "Epoch 56/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4548 - accuracy: 0.7717 - mae: 0.3026\n",
            "Epoch 57/100\n",
            "920/920 [==============================] - 0s 82us/step - loss: 0.4516 - accuracy: 0.7870 - mae: 0.2986\n",
            "Epoch 58/100\n",
            "920/920 [==============================] - 0s 80us/step - loss: 0.4416 - accuracy: 0.7902 - mae: 0.2916\n",
            "Epoch 59/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4464 - accuracy: 0.7815 - mae: 0.2965\n",
            "Epoch 60/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4338 - accuracy: 0.7957 - mae: 0.2879\n",
            "Epoch 61/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4479 - accuracy: 0.7783 - mae: 0.2950\n",
            "Epoch 62/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4422 - accuracy: 0.7804 - mae: 0.2921\n",
            "Epoch 63/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4336 - accuracy: 0.7783 - mae: 0.2898\n",
            "Epoch 64/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4329 - accuracy: 0.7783 - mae: 0.2884\n",
            "Epoch 65/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4219 - accuracy: 0.7826 - mae: 0.2826\n",
            "Epoch 66/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.4234 - accuracy: 0.7902 - mae: 0.2860\n",
            "Epoch 67/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4267 - accuracy: 0.7902 - mae: 0.2801\n",
            "Epoch 68/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4449 - accuracy: 0.7815 - mae: 0.2886\n",
            "Epoch 69/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4502 - accuracy: 0.7772 - mae: 0.2940\n",
            "Epoch 70/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4387 - accuracy: 0.7750 - mae: 0.2954\n",
            "Epoch 71/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4223 - accuracy: 0.7946 - mae: 0.2780\n",
            "Epoch 72/100\n",
            "920/920 [==============================] - 0s 76us/step - loss: 0.4307 - accuracy: 0.7902 - mae: 0.2834\n",
            "Epoch 73/100\n",
            "920/920 [==============================] - 0s 87us/step - loss: 0.4242 - accuracy: 0.7913 - mae: 0.2821\n",
            "Epoch 74/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4178 - accuracy: 0.8000 - mae: 0.2760\n",
            "Epoch 75/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4080 - accuracy: 0.8130 - mae: 0.2718\n",
            "Epoch 76/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4150 - accuracy: 0.7913 - mae: 0.2762\n",
            "Epoch 77/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4179 - accuracy: 0.8098 - mae: 0.2706\n",
            "Epoch 78/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4097 - accuracy: 0.8054 - mae: 0.2708\n",
            "Epoch 79/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.4144 - accuracy: 0.8120 - mae: 0.2755\n",
            "Epoch 80/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.4089 - accuracy: 0.8109 - mae: 0.2669\n",
            "Epoch 81/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4083 - accuracy: 0.8043 - mae: 0.2702\n",
            "Epoch 82/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4087 - accuracy: 0.8152 - mae: 0.2686\n",
            "Epoch 83/100\n",
            "920/920 [==============================] - 0s 77us/step - loss: 0.4126 - accuracy: 0.8109 - mae: 0.2697\n",
            "Epoch 84/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4033 - accuracy: 0.8076 - mae: 0.2668\n",
            "Epoch 85/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4139 - accuracy: 0.8065 - mae: 0.2691\n",
            "Epoch 86/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4054 - accuracy: 0.8120 - mae: 0.2678\n",
            "Epoch 87/100\n",
            "920/920 [==============================] - 0s 65us/step - loss: 0.4107 - accuracy: 0.8000 - mae: 0.2700\n",
            "Epoch 88/100\n",
            "920/920 [==============================] - 0s 66us/step - loss: 0.3940 - accuracy: 0.8217 - mae: 0.2611\n",
            "Epoch 89/100\n",
            "920/920 [==============================] - 0s 69us/step - loss: 0.4034 - accuracy: 0.8174 - mae: 0.2688\n",
            "Epoch 90/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.3913 - accuracy: 0.8141 - mae: 0.2603\n",
            "Epoch 91/100\n",
            "920/920 [==============================] - 0s 75us/step - loss: 0.4033 - accuracy: 0.8087 - mae: 0.2646\n",
            "Epoch 92/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.3990 - accuracy: 0.8228 - mae: 0.2602\n",
            "Epoch 93/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.3935 - accuracy: 0.8174 - mae: 0.2599\n",
            "Epoch 94/100\n",
            "920/920 [==============================] - 0s 71us/step - loss: 0.4079 - accuracy: 0.8196 - mae: 0.2635\n",
            "Epoch 95/100\n",
            "920/920 [==============================] - 0s 68us/step - loss: 0.4079 - accuracy: 0.8022 - mae: 0.2609\n",
            "Epoch 96/100\n",
            "920/920 [==============================] - 0s 74us/step - loss: 0.3897 - accuracy: 0.8217 - mae: 0.2592\n",
            "Epoch 97/100\n",
            "920/920 [==============================] - 0s 70us/step - loss: 0.3903 - accuracy: 0.8217 - mae: 0.2588\n",
            "Epoch 98/100\n",
            "920/920 [==============================] - 0s 72us/step - loss: 0.4042 - accuracy: 0.8217 - mae: 0.2577\n",
            "Epoch 99/100\n",
            "920/920 [==============================] - 0s 67us/step - loss: 0.3833 - accuracy: 0.8152 - mae: 0.2521\n",
            "Epoch 100/100\n",
            "920/920 [==============================] - 0s 73us/step - loss: 0.3869 - accuracy: 0.8207 - mae: 0.2530\n",
            "Best: 0.732099 using {'kc__activation': 'tanh', 'kc__init': 'uniform'}\n",
            "Train: 0.826124 (0.005224) // Test : 0.713646 (0.042520) with: {'kc__activation': 'softmax', 'kc__init': 'uniform'}\n",
            "Train: 0.687574 (0.004411) // Test : 0.687350 (0.017736) with: {'kc__activation': 'softmax', 'kc__init': 'zeros'}\n",
            "Train: 0.828305 (0.013103) // Test : 0.709679 (0.034356) with: {'kc__activation': 'softmax', 'kc__init': 'normal'}\n",
            "Train: 0.833910 (0.006690) // Test : 0.688802 (0.039058) with: {'kc__activation': 'softmax', 'kc__init': 'glorot_uniform'}\n",
            "Train: 0.807142 (0.060846) // Test : 0.718736 (0.026069) with: {'kc__activation': 'relu', 'kc__init': 'uniform'}\n",
            "Train: 0.687574 (0.004411) // Test : 0.687350 (0.017736) with: {'kc__activation': 'relu', 'kc__init': 'zeros'}\n",
            "Train: 0.821841 (0.030623) // Test : 0.712798 (0.053964) with: {'kc__activation': 'relu', 'kc__init': 'normal'}\n",
            "Train: 0.839182 (0.008083) // Test : 0.710657 (0.037035) with: {'kc__activation': 'relu', 'kc__init': 'glorot_uniform'}\n",
            "Train: 0.826238 (0.013224) // Test : 0.732099 (0.024595) with: {'kc__activation': 'tanh', 'kc__init': 'uniform'}\n",
            "Train: 0.687574 (0.004411) // Test : 0.687350 (0.017736) with: {'kc__activation': 'tanh', 'kc__init': 'zeros'}\n",
            "Train: 0.828363 (0.012667) // Test : 0.715713 (0.022990) with: {'kc__activation': 'tanh', 'kc__init': 'normal'}\n",
            "Train: 0.861896 (0.009139) // Test : 0.719628 (0.028423) with: {'kc__activation': 'tanh', 'kc__init': 'glorot_uniform'}\n",
            "Train: 0.710998 (0.008946) // Test : 0.695556 (0.050711) with: {'kc__activation': 'linear', 'kc__init': 'uniform'}\n",
            "Train: 0.687574 (0.004411) // Test : 0.687350 (0.017736) with: {'kc__activation': 'linear', 'kc__init': 'zeros'}\n",
            "Train: 0.703002 (0.012568) // Test : 0.687384 (0.043543) with: {'kc__activation': 'linear', 'kc__init': 'normal'}\n",
            "Train: 0.717031 (0.006474) // Test : 0.692790 (0.053880) with: {'kc__activation': 'linear', 'kc__init': 'glorot_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nRkm_SLgL5h",
        "colab_type": "text"
      },
      "source": [
        "### Train the best model with tuned hyperparameters\n",
        "Neuron in first hidden layer = 12 (12)\n",
        "\n",
        "---\n",
        "Neuron in second hidden layer = 4 (3)\n",
        "\n",
        "---\n",
        "Activation function = tanh (tanh)\n",
        "\n",
        "---\n",
        "Initialization = uniform (normal)\n",
        "\n",
        "---\n",
        "Dropout = 0.00(0.05\n",
        "\n",
        "---\n",
        "Adam initial Learning Rate = 0.005(0.005)\n",
        "\n",
        "---\n",
        "Batch Size = 16    (46 (according training and validation test size))\n",
        "\n",
        "---\n",
        "Epoch = 100\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "135nH6XNzgZ2",
        "colab_type": "code",
        "outputId": "ab336556-6623-4bbc-a582-5e7cdbb99c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP9B1UYJgJs0",
        "colab_type": "code",
        "outputId": "0965ce02-4295-43e3-ff76-00714d6c46d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model_1():# these hyperparameters were drived from tuning later on ......\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12,input_dim = 19,kernel_initializer = 'uniform' ,activation = 'tanh'))\n",
        "    model.add(Dropout(0.15))\n",
        "    model.add(Dense(4,input_dim = 12,kernel_initializer =  'uniform' ,activation = 'tanh'))\n",
        "    model.add(Dropout(0.15))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    opt = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy','mae'])\n",
        "    return model\n",
        "\n",
        "best_model = create_model_1()\n",
        "print(best_model.summary())\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=\"/tmp/model2.hdf5\",\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25, restore_best_weights=True)                             # pat 25 false 0.1 10 0..005 0.4807\n",
        "                                                                                                                                  # pat 20 true  0.12 10 0.004 0.4694\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.05 , patience= 5)                                                                                #  pat 20 true  0.13 10 0.003 0.483\n",
        "                                                                                                                                  #              0.15 7  0.003 0.4798\n",
        "history = best_model.fit(\n",
        "          x_train, \n",
        "          y_train, \n",
        "          \n",
        "          epochs=250,\n",
        "          batch_size=16,\n",
        "          validation_split=0.2,\n",
        "         \n",
        "          callbacks=[es,checkpoint,],\n",
        "          )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_55 (Dense)             (None, 12)                240       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 4)                 52        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 297\n",
            "Trainable params: 297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 736 samples, validate on 184 samples\n",
            "Epoch 1/250\n",
            "736/736 [==============================] - 0s 290us/step - loss: 0.6770 - accuracy: 0.5340 - mae: 0.4899 - val_loss: 0.6508 - val_accuracy: 0.5978 - val_mae: 0.4740\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.65080, saving model to /tmp/model2.hdf5\n",
            "Epoch 2/250\n",
            "736/736 [==============================] - 0s 83us/step - loss: 0.6518 - accuracy: 0.5856 - mae: 0.4708 - val_loss: 0.6213 - val_accuracy: 0.6141 - val_mae: 0.4521\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.65080 to 0.62127, saving model to /tmp/model2.hdf5\n",
            "Epoch 3/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.6370 - accuracy: 0.5951 - mae: 0.4548 - val_loss: 0.6089 - val_accuracy: 0.6413 - val_mae: 0.4421\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.62127 to 0.60886, saving model to /tmp/model2.hdf5\n",
            "Epoch 4/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.6316 - accuracy: 0.6114 - mae: 0.4512 - val_loss: 0.6011 - val_accuracy: 0.6630 - val_mae: 0.4355\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.60886 to 0.60110, saving model to /tmp/model2.hdf5\n",
            "Epoch 5/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.6293 - accuracy: 0.6196 - mae: 0.4466 - val_loss: 0.5922 - val_accuracy: 0.6739 - val_mae: 0.4292\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.60110 to 0.59220, saving model to /tmp/model2.hdf5\n",
            "Epoch 6/250\n",
            "736/736 [==============================] - 0s 105us/step - loss: 0.6233 - accuracy: 0.6372 - mae: 0.4418 - val_loss: 0.5918 - val_accuracy: 0.6793 - val_mae: 0.4294\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.59220 to 0.59183, saving model to /tmp/model2.hdf5\n",
            "Epoch 7/250\n",
            "736/736 [==============================] - 0s 122us/step - loss: 0.6148 - accuracy: 0.6508 - mae: 0.4391 - val_loss: 0.5873 - val_accuracy: 0.7011 - val_mae: 0.4269\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.59183 to 0.58728, saving model to /tmp/model2.hdf5\n",
            "Epoch 8/250\n",
            "736/736 [==============================] - 0s 106us/step - loss: 0.6044 - accuracy: 0.6671 - mae: 0.4313 - val_loss: 0.5808 - val_accuracy: 0.7011 - val_mae: 0.4200\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.58728 to 0.58076, saving model to /tmp/model2.hdf5\n",
            "Epoch 9/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.6096 - accuracy: 0.6753 - mae: 0.4339 - val_loss: 0.5797 - val_accuracy: 0.7065 - val_mae: 0.4186\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.58076 to 0.57969, saving model to /tmp/model2.hdf5\n",
            "Epoch 10/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5992 - accuracy: 0.6753 - mae: 0.4235 - val_loss: 0.5817 - val_accuracy: 0.7174 - val_mae: 0.4185\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.57969\n",
            "Epoch 11/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.6059 - accuracy: 0.6793 - mae: 0.4266 - val_loss: 0.5894 - val_accuracy: 0.7011 - val_mae: 0.4205\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.57969\n",
            "Epoch 12/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.6003 - accuracy: 0.6861 - mae: 0.4216 - val_loss: 0.5699 - val_accuracy: 0.7174 - val_mae: 0.4093\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.57969 to 0.56986, saving model to /tmp/model2.hdf5\n",
            "Epoch 13/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5927 - accuracy: 0.6957 - mae: 0.4185 - val_loss: 0.5680 - val_accuracy: 0.7120 - val_mae: 0.4071\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.56986 to 0.56805, saving model to /tmp/model2.hdf5\n",
            "Epoch 14/250\n",
            "736/736 [==============================] - 0s 109us/step - loss: 0.5904 - accuracy: 0.6943 - mae: 0.4178 - val_loss: 0.5577 - val_accuracy: 0.7228 - val_mae: 0.3974\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.56805 to 0.55772, saving model to /tmp/model2.hdf5\n",
            "Epoch 15/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5902 - accuracy: 0.6916 - mae: 0.4172 - val_loss: 0.5557 - val_accuracy: 0.7283 - val_mae: 0.3943\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.55772 to 0.55573, saving model to /tmp/model2.hdf5\n",
            "Epoch 16/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5954 - accuracy: 0.6929 - mae: 0.4114 - val_loss: 0.5545 - val_accuracy: 0.7391 - val_mae: 0.3945\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.55573 to 0.55454, saving model to /tmp/model2.hdf5\n",
            "Epoch 17/250\n",
            "736/736 [==============================] - 0s 100us/step - loss: 0.5882 - accuracy: 0.6984 - mae: 0.4129 - val_loss: 0.5497 - val_accuracy: 0.7446 - val_mae: 0.3906\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.55454 to 0.54973, saving model to /tmp/model2.hdf5\n",
            "Epoch 18/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5877 - accuracy: 0.6834 - mae: 0.4137 - val_loss: 0.5483 - val_accuracy: 0.7500 - val_mae: 0.3888\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.54973 to 0.54834, saving model to /tmp/model2.hdf5\n",
            "Epoch 19/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5834 - accuracy: 0.6984 - mae: 0.4070 - val_loss: 0.5660 - val_accuracy: 0.7228 - val_mae: 0.4006\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.54834\n",
            "Epoch 20/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5766 - accuracy: 0.6970 - mae: 0.4054 - val_loss: 0.5542 - val_accuracy: 0.7391 - val_mae: 0.3934\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.54834\n",
            "Epoch 21/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5823 - accuracy: 0.7038 - mae: 0.4064 - val_loss: 0.5536 - val_accuracy: 0.7554 - val_mae: 0.3946\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.54834\n",
            "Epoch 22/250\n",
            "736/736 [==============================] - 0s 105us/step - loss: 0.5747 - accuracy: 0.6889 - mae: 0.4031 - val_loss: 0.5607 - val_accuracy: 0.7283 - val_mae: 0.3961\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.54834\n",
            "Epoch 23/250\n",
            "736/736 [==============================] - 0s 100us/step - loss: 0.5724 - accuracy: 0.7065 - mae: 0.4019 - val_loss: 0.5479 - val_accuracy: 0.7554 - val_mae: 0.3864\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.54834 to 0.54786, saving model to /tmp/model2.hdf5\n",
            "Epoch 24/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5715 - accuracy: 0.7065 - mae: 0.3993 - val_loss: 0.5466 - val_accuracy: 0.7609 - val_mae: 0.3870\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.54786 to 0.54660, saving model to /tmp/model2.hdf5\n",
            "Epoch 25/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5685 - accuracy: 0.7024 - mae: 0.3964 - val_loss: 0.5397 - val_accuracy: 0.7609 - val_mae: 0.3782\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.54660 to 0.53972, saving model to /tmp/model2.hdf5\n",
            "Epoch 26/250\n",
            "736/736 [==============================] - 0s 104us/step - loss: 0.5783 - accuracy: 0.6916 - mae: 0.4012 - val_loss: 0.5556 - val_accuracy: 0.7500 - val_mae: 0.3923\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.53972\n",
            "Epoch 27/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5701 - accuracy: 0.6970 - mae: 0.3975 - val_loss: 0.5426 - val_accuracy: 0.7663 - val_mae: 0.3838\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.53972\n",
            "Epoch 28/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5763 - accuracy: 0.7011 - mae: 0.3960 - val_loss: 0.5428 - val_accuracy: 0.7772 - val_mae: 0.3840\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.53972\n",
            "Epoch 29/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5621 - accuracy: 0.6957 - mae: 0.3940 - val_loss: 0.5673 - val_accuracy: 0.7283 - val_mae: 0.3946\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.53972\n",
            "Epoch 30/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.5653 - accuracy: 0.7174 - mae: 0.3969 - val_loss: 0.5550 - val_accuracy: 0.7500 - val_mae: 0.3883\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.53972\n",
            "Epoch 31/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.5565 - accuracy: 0.6984 - mae: 0.3870 - val_loss: 0.5369 - val_accuracy: 0.7717 - val_mae: 0.3783\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.53972 to 0.53688, saving model to /tmp/model2.hdf5\n",
            "Epoch 32/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5564 - accuracy: 0.7242 - mae: 0.3876 - val_loss: 0.5440 - val_accuracy: 0.7663 - val_mae: 0.3826\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.53688\n",
            "Epoch 33/250\n",
            "736/736 [==============================] - 0s 118us/step - loss: 0.5636 - accuracy: 0.7079 - mae: 0.3901 - val_loss: 0.5333 - val_accuracy: 0.7663 - val_mae: 0.3742\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.53688 to 0.53325, saving model to /tmp/model2.hdf5\n",
            "Epoch 34/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5573 - accuracy: 0.7079 - mae: 0.3872 - val_loss: 0.5317 - val_accuracy: 0.7609 - val_mae: 0.3699\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.53325 to 0.53167, saving model to /tmp/model2.hdf5\n",
            "Epoch 35/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5591 - accuracy: 0.7120 - mae: 0.3836 - val_loss: 0.5301 - val_accuracy: 0.7609 - val_mae: 0.3688\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.53167 to 0.53007, saving model to /tmp/model2.hdf5\n",
            "Epoch 36/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5470 - accuracy: 0.7242 - mae: 0.3813 - val_loss: 0.5451 - val_accuracy: 0.7500 - val_mae: 0.3825\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.53007\n",
            "Epoch 37/250\n",
            "736/736 [==============================] - 0s 102us/step - loss: 0.5560 - accuracy: 0.7092 - mae: 0.3844 - val_loss: 0.5341 - val_accuracy: 0.7554 - val_mae: 0.3743\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.53007\n",
            "Epoch 38/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5486 - accuracy: 0.7106 - mae: 0.3828 - val_loss: 0.5257 - val_accuracy: 0.7663 - val_mae: 0.3663\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.53007 to 0.52570, saving model to /tmp/model2.hdf5\n",
            "Epoch 39/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.5457 - accuracy: 0.7065 - mae: 0.3794 - val_loss: 0.5323 - val_accuracy: 0.7446 - val_mae: 0.3685\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.52570\n",
            "Epoch 40/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5583 - accuracy: 0.7092 - mae: 0.3828 - val_loss: 0.5297 - val_accuracy: 0.7446 - val_mae: 0.3636\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.52570\n",
            "Epoch 41/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5514 - accuracy: 0.7038 - mae: 0.3813 - val_loss: 0.5264 - val_accuracy: 0.7663 - val_mae: 0.3685\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.52570\n",
            "Epoch 42/250\n",
            "736/736 [==============================] - 0s 88us/step - loss: 0.5538 - accuracy: 0.7160 - mae: 0.3844 - val_loss: 0.5310 - val_accuracy: 0.7554 - val_mae: 0.3686\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.52570\n",
            "Epoch 43/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5550 - accuracy: 0.7011 - mae: 0.3811 - val_loss: 0.5246 - val_accuracy: 0.7717 - val_mae: 0.3667\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.52570 to 0.52461, saving model to /tmp/model2.hdf5\n",
            "Epoch 44/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5390 - accuracy: 0.7106 - mae: 0.3757 - val_loss: 0.5196 - val_accuracy: 0.7663 - val_mae: 0.3607\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.52461 to 0.51962, saving model to /tmp/model2.hdf5\n",
            "Epoch 45/250\n",
            "736/736 [==============================] - 0s 99us/step - loss: 0.5369 - accuracy: 0.7323 - mae: 0.3693 - val_loss: 0.5267 - val_accuracy: 0.7609 - val_mae: 0.3667\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.51962\n",
            "Epoch 46/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5437 - accuracy: 0.7242 - mae: 0.3758 - val_loss: 0.5185 - val_accuracy: 0.7663 - val_mae: 0.3581\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.51962 to 0.51852, saving model to /tmp/model2.hdf5\n",
            "Epoch 47/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5494 - accuracy: 0.7106 - mae: 0.3812 - val_loss: 0.5197 - val_accuracy: 0.7663 - val_mae: 0.3593\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.51852\n",
            "Epoch 48/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.5362 - accuracy: 0.7160 - mae: 0.3696 - val_loss: 0.5157 - val_accuracy: 0.7663 - val_mae: 0.3557\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.51852 to 0.51571, saving model to /tmp/model2.hdf5\n",
            "Epoch 49/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5442 - accuracy: 0.7242 - mae: 0.3727 - val_loss: 0.5225 - val_accuracy: 0.7663 - val_mae: 0.3632\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.51571\n",
            "Epoch 50/250\n",
            "736/736 [==============================] - 0s 97us/step - loss: 0.5367 - accuracy: 0.7106 - mae: 0.3722 - val_loss: 0.5191 - val_accuracy: 0.7663 - val_mae: 0.3578\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.51571\n",
            "Epoch 51/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5470 - accuracy: 0.7310 - mae: 0.3760 - val_loss: 0.5179 - val_accuracy: 0.7826 - val_mae: 0.3585\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.51571\n",
            "Epoch 52/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5350 - accuracy: 0.7133 - mae: 0.3682 - val_loss: 0.5130 - val_accuracy: 0.7826 - val_mae: 0.3561\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.51571 to 0.51303, saving model to /tmp/model2.hdf5\n",
            "Epoch 53/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.5397 - accuracy: 0.7106 - mae: 0.3706 - val_loss: 0.5229 - val_accuracy: 0.7554 - val_mae: 0.3627\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.51303\n",
            "Epoch 54/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5375 - accuracy: 0.7242 - mae: 0.3667 - val_loss: 0.5117 - val_accuracy: 0.7554 - val_mae: 0.3481\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.51303 to 0.51169, saving model to /tmp/model2.hdf5\n",
            "Epoch 55/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5398 - accuracy: 0.7188 - mae: 0.3712 - val_loss: 0.5132 - val_accuracy: 0.7772 - val_mae: 0.3556\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.51169\n",
            "Epoch 56/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.5466 - accuracy: 0.7092 - mae: 0.3707 - val_loss: 0.5262 - val_accuracy: 0.7500 - val_mae: 0.3663\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.51169\n",
            "Epoch 57/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5590 - accuracy: 0.7038 - mae: 0.3769 - val_loss: 0.5142 - val_accuracy: 0.7554 - val_mae: 0.3562\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.51169\n",
            "Epoch 58/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5341 - accuracy: 0.7242 - mae: 0.3682 - val_loss: 0.5150 - val_accuracy: 0.7609 - val_mae: 0.3545\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.51169\n",
            "Epoch 59/250\n",
            "736/736 [==============================] - 0s 95us/step - loss: 0.5291 - accuracy: 0.7242 - mae: 0.3662 - val_loss: 0.5130 - val_accuracy: 0.7717 - val_mae: 0.3482\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.51169\n",
            "Epoch 60/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5498 - accuracy: 0.7147 - mae: 0.3672 - val_loss: 0.5290 - val_accuracy: 0.7500 - val_mae: 0.3669\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.51169\n",
            "Epoch 61/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5251 - accuracy: 0.7228 - mae: 0.3644 - val_loss: 0.5453 - val_accuracy: 0.7283 - val_mae: 0.3650\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.51169\n",
            "Epoch 62/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5291 - accuracy: 0.7296 - mae: 0.3644 - val_loss: 0.5175 - val_accuracy: 0.7554 - val_mae: 0.3585\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.51169\n",
            "Epoch 63/250\n",
            "736/736 [==============================] - 0s 95us/step - loss: 0.5377 - accuracy: 0.7079 - mae: 0.3686 - val_loss: 0.5113 - val_accuracy: 0.7935 - val_mae: 0.3531\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.51169 to 0.51132, saving model to /tmp/model2.hdf5\n",
            "Epoch 64/250\n",
            "736/736 [==============================] - 0s 101us/step - loss: 0.5319 - accuracy: 0.7323 - mae: 0.3640 - val_loss: 0.5352 - val_accuracy: 0.7283 - val_mae: 0.3655\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.51132\n",
            "Epoch 65/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5262 - accuracy: 0.7296 - mae: 0.3623 - val_loss: 0.5116 - val_accuracy: 0.7717 - val_mae: 0.3486\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.51132\n",
            "Epoch 66/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.5373 - accuracy: 0.7160 - mae: 0.3649 - val_loss: 0.5170 - val_accuracy: 0.7663 - val_mae: 0.3550\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.51132\n",
            "Epoch 67/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.5357 - accuracy: 0.7188 - mae: 0.3638 - val_loss: 0.5220 - val_accuracy: 0.7337 - val_mae: 0.3581\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.51132\n",
            "Epoch 68/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5360 - accuracy: 0.7120 - mae: 0.3656 - val_loss: 0.5217 - val_accuracy: 0.7446 - val_mae: 0.3623\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.51132\n",
            "Epoch 69/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5318 - accuracy: 0.7147 - mae: 0.3657 - val_loss: 0.5107 - val_accuracy: 0.7663 - val_mae: 0.3513\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.51132 to 0.51073, saving model to /tmp/model2.hdf5\n",
            "Epoch 70/250\n",
            "736/736 [==============================] - 0s 83us/step - loss: 0.5261 - accuracy: 0.7269 - mae: 0.3627 - val_loss: 0.5096 - val_accuracy: 0.7717 - val_mae: 0.3519\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.51073 to 0.50964, saving model to /tmp/model2.hdf5\n",
            "Epoch 71/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5359 - accuracy: 0.7160 - mae: 0.3642 - val_loss: 0.5185 - val_accuracy: 0.7554 - val_mae: 0.3562\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.50964\n",
            "Epoch 72/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.5299 - accuracy: 0.7228 - mae: 0.3618 - val_loss: 0.5108 - val_accuracy: 0.7500 - val_mae: 0.3545\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.50964\n",
            "Epoch 73/250\n",
            "736/736 [==============================] - 0s 97us/step - loss: 0.5358 - accuracy: 0.7188 - mae: 0.3628 - val_loss: 0.5061 - val_accuracy: 0.7446 - val_mae: 0.3529\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.50964 to 0.50609, saving model to /tmp/model2.hdf5\n",
            "Epoch 74/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5326 - accuracy: 0.7133 - mae: 0.3659 - val_loss: 0.5032 - val_accuracy: 0.7663 - val_mae: 0.3511\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.50609 to 0.50323, saving model to /tmp/model2.hdf5\n",
            "Epoch 75/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5329 - accuracy: 0.7514 - mae: 0.3634 - val_loss: 0.5028 - val_accuracy: 0.7772 - val_mae: 0.3504\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.50323 to 0.50279, saving model to /tmp/model2.hdf5\n",
            "Epoch 76/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5300 - accuracy: 0.7215 - mae: 0.3643 - val_loss: 0.5436 - val_accuracy: 0.7446 - val_mae: 0.3698\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.50279\n",
            "Epoch 77/250\n",
            "736/736 [==============================] - 0s 106us/step - loss: 0.5323 - accuracy: 0.7133 - mae: 0.3603 - val_loss: 0.5065 - val_accuracy: 0.7663 - val_mae: 0.3531\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.50279\n",
            "Epoch 78/250\n",
            "736/736 [==============================] - 0s 114us/step - loss: 0.5321 - accuracy: 0.7242 - mae: 0.3646 - val_loss: 0.5013 - val_accuracy: 0.7772 - val_mae: 0.3470\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.50279 to 0.50134, saving model to /tmp/model2.hdf5\n",
            "Epoch 79/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.5190 - accuracy: 0.7201 - mae: 0.3564 - val_loss: 0.5011 - val_accuracy: 0.7717 - val_mae: 0.3469\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.50134 to 0.50112, saving model to /tmp/model2.hdf5\n",
            "Epoch 80/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5274 - accuracy: 0.7269 - mae: 0.3593 - val_loss: 0.4971 - val_accuracy: 0.7717 - val_mae: 0.3440\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.50112 to 0.49708, saving model to /tmp/model2.hdf5\n",
            "Epoch 81/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5270 - accuracy: 0.7160 - mae: 0.3616 - val_loss: 0.5001 - val_accuracy: 0.7663 - val_mae: 0.3445\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.49708\n",
            "Epoch 82/250\n",
            "736/736 [==============================] - 0s 109us/step - loss: 0.5228 - accuracy: 0.7133 - mae: 0.3608 - val_loss: 0.5102 - val_accuracy: 0.7446 - val_mae: 0.3535\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.49708\n",
            "Epoch 83/250\n",
            "736/736 [==============================] - 0s 119us/step - loss: 0.5147 - accuracy: 0.7337 - mae: 0.3541 - val_loss: 0.5056 - val_accuracy: 0.7826 - val_mae: 0.3425\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.49708\n",
            "Epoch 84/250\n",
            "736/736 [==============================] - 0s 112us/step - loss: 0.5210 - accuracy: 0.7337 - mae: 0.3538 - val_loss: 0.4976 - val_accuracy: 0.7772 - val_mae: 0.3438\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.49708\n",
            "Epoch 85/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5111 - accuracy: 0.7378 - mae: 0.3511 - val_loss: 0.5008 - val_accuracy: 0.7717 - val_mae: 0.3472\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.49708\n",
            "Epoch 86/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5175 - accuracy: 0.7378 - mae: 0.3552 - val_loss: 0.5061 - val_accuracy: 0.7663 - val_mae: 0.3475\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.49708\n",
            "Epoch 87/250\n",
            "736/736 [==============================] - 0s 99us/step - loss: 0.5174 - accuracy: 0.7283 - mae: 0.3536 - val_loss: 0.4968 - val_accuracy: 0.7717 - val_mae: 0.3407\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.49708 to 0.49683, saving model to /tmp/model2.hdf5\n",
            "Epoch 88/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5126 - accuracy: 0.7446 - mae: 0.3508 - val_loss: 0.4959 - val_accuracy: 0.7663 - val_mae: 0.3386\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.49683 to 0.49589, saving model to /tmp/model2.hdf5\n",
            "Epoch 89/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5336 - accuracy: 0.7065 - mae: 0.3603 - val_loss: 0.5070 - val_accuracy: 0.7554 - val_mae: 0.3396\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.49589\n",
            "Epoch 90/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5332 - accuracy: 0.7405 - mae: 0.3521 - val_loss: 0.4995 - val_accuracy: 0.7554 - val_mae: 0.3429\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.49589\n",
            "Epoch 91/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5489 - accuracy: 0.7242 - mae: 0.3671 - val_loss: 0.5248 - val_accuracy: 0.7446 - val_mae: 0.3543\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.49589\n",
            "Epoch 92/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5351 - accuracy: 0.7147 - mae: 0.3605 - val_loss: 0.5273 - val_accuracy: 0.7446 - val_mae: 0.3601\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.49589\n",
            "Epoch 93/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5214 - accuracy: 0.7323 - mae: 0.3569 - val_loss: 0.4963 - val_accuracy: 0.7826 - val_mae: 0.3383\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.49589\n",
            "Epoch 94/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5355 - accuracy: 0.7147 - mae: 0.3579 - val_loss: 0.4982 - val_accuracy: 0.7826 - val_mae: 0.3426\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.49589\n",
            "Epoch 95/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5295 - accuracy: 0.7215 - mae: 0.3601 - val_loss: 0.4965 - val_accuracy: 0.7717 - val_mae: 0.3439\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.49589\n",
            "Epoch 96/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.5201 - accuracy: 0.7364 - mae: 0.3541 - val_loss: 0.4963 - val_accuracy: 0.7663 - val_mae: 0.3425\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.49589\n",
            "Epoch 97/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5257 - accuracy: 0.7378 - mae: 0.3507 - val_loss: 0.5007 - val_accuracy: 0.7609 - val_mae: 0.3497\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.49589\n",
            "Epoch 98/250\n",
            "736/736 [==============================] - 0s 95us/step - loss: 0.5171 - accuracy: 0.7323 - mae: 0.3580 - val_loss: 0.4945 - val_accuracy: 0.7609 - val_mae: 0.3437\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.49589 to 0.49448, saving model to /tmp/model2.hdf5\n",
            "Epoch 99/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5037 - accuracy: 0.7228 - mae: 0.3495 - val_loss: 0.4945 - val_accuracy: 0.7826 - val_mae: 0.3378\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.49448\n",
            "Epoch 100/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5144 - accuracy: 0.7188 - mae: 0.3534 - val_loss: 0.4916 - val_accuracy: 0.7717 - val_mae: 0.3384\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.49448 to 0.49156, saving model to /tmp/model2.hdf5\n",
            "Epoch 101/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5291 - accuracy: 0.7228 - mae: 0.3573 - val_loss: 0.5089 - val_accuracy: 0.7717 - val_mae: 0.3431\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.49156\n",
            "Epoch 102/250\n",
            "736/736 [==============================] - 0s 99us/step - loss: 0.5202 - accuracy: 0.7215 - mae: 0.3542 - val_loss: 0.4984 - val_accuracy: 0.7663 - val_mae: 0.3358\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.49156\n",
            "Epoch 103/250\n",
            "736/736 [==============================] - 0s 97us/step - loss: 0.5309 - accuracy: 0.7337 - mae: 0.3556 - val_loss: 0.4928 - val_accuracy: 0.7663 - val_mae: 0.3405\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.49156\n",
            "Epoch 104/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5163 - accuracy: 0.7296 - mae: 0.3534 - val_loss: 0.5018 - val_accuracy: 0.7772 - val_mae: 0.3426\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.49156\n",
            "Epoch 105/250\n",
            "736/736 [==============================] - 0s 84us/step - loss: 0.5211 - accuracy: 0.7351 - mae: 0.3546 - val_loss: 0.4898 - val_accuracy: 0.7772 - val_mae: 0.3370\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.49156 to 0.48984, saving model to /tmp/model2.hdf5\n",
            "Epoch 106/250\n",
            "736/736 [==============================] - 0s 88us/step - loss: 0.5299 - accuracy: 0.7242 - mae: 0.3591 - val_loss: 0.4970 - val_accuracy: 0.7663 - val_mae: 0.3350\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.48984\n",
            "Epoch 107/250\n",
            "736/736 [==============================] - 0s 115us/step - loss: 0.5438 - accuracy: 0.7201 - mae: 0.3620 - val_loss: 0.4883 - val_accuracy: 0.7609 - val_mae: 0.3376\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.48984 to 0.48830, saving model to /tmp/model2.hdf5\n",
            "Epoch 108/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.5193 - accuracy: 0.7147 - mae: 0.3507 - val_loss: 0.4938 - val_accuracy: 0.7772 - val_mae: 0.3415\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.48830\n",
            "Epoch 109/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5179 - accuracy: 0.7269 - mae: 0.3524 - val_loss: 0.5021 - val_accuracy: 0.7554 - val_mae: 0.3482\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.48830\n",
            "Epoch 110/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5228 - accuracy: 0.7255 - mae: 0.3549 - val_loss: 0.4915 - val_accuracy: 0.7663 - val_mae: 0.3429\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.48830\n",
            "Epoch 111/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5139 - accuracy: 0.7351 - mae: 0.3560 - val_loss: 0.4928 - val_accuracy: 0.7609 - val_mae: 0.3413\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.48830\n",
            "Epoch 112/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5190 - accuracy: 0.7364 - mae: 0.3512 - val_loss: 0.4843 - val_accuracy: 0.7663 - val_mae: 0.3353\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.48830 to 0.48426, saving model to /tmp/model2.hdf5\n",
            "Epoch 113/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5126 - accuracy: 0.7446 - mae: 0.3520 - val_loss: 0.4857 - val_accuracy: 0.7772 - val_mae: 0.3338\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.48426\n",
            "Epoch 114/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5252 - accuracy: 0.7269 - mae: 0.3509 - val_loss: 0.4876 - val_accuracy: 0.7772 - val_mae: 0.3346\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.48426\n",
            "Epoch 115/250\n",
            "736/736 [==============================] - 0s 112us/step - loss: 0.5241 - accuracy: 0.7337 - mae: 0.3546 - val_loss: 0.4885 - val_accuracy: 0.7717 - val_mae: 0.3386\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.48426\n",
            "Epoch 116/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5210 - accuracy: 0.7405 - mae: 0.3544 - val_loss: 0.4878 - val_accuracy: 0.7826 - val_mae: 0.3337\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.48426\n",
            "Epoch 117/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.5208 - accuracy: 0.7215 - mae: 0.3536 - val_loss: 0.4890 - val_accuracy: 0.7880 - val_mae: 0.3350\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.48426\n",
            "Epoch 118/250\n",
            "736/736 [==============================] - 0s 104us/step - loss: 0.5154 - accuracy: 0.7351 - mae: 0.3499 - val_loss: 0.4920 - val_accuracy: 0.7609 - val_mae: 0.3399\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.48426\n",
            "Epoch 119/250\n",
            "736/736 [==============================] - 0s 102us/step - loss: 0.5233 - accuracy: 0.7323 - mae: 0.3537 - val_loss: 0.4930 - val_accuracy: 0.7609 - val_mae: 0.3408\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.48426\n",
            "Epoch 120/250\n",
            "736/736 [==============================] - 0s 95us/step - loss: 0.5045 - accuracy: 0.7405 - mae: 0.3448 - val_loss: 0.4896 - val_accuracy: 0.7554 - val_mae: 0.3348\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.48426\n",
            "Epoch 121/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5004 - accuracy: 0.7514 - mae: 0.3458 - val_loss: 0.4858 - val_accuracy: 0.7663 - val_mae: 0.3328\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.48426\n",
            "Epoch 122/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5121 - accuracy: 0.7500 - mae: 0.3449 - val_loss: 0.5005 - val_accuracy: 0.7500 - val_mae: 0.3387\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.48426\n",
            "Epoch 123/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5065 - accuracy: 0.7269 - mae: 0.3477 - val_loss: 0.5132 - val_accuracy: 0.7391 - val_mae: 0.3530\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.48426\n",
            "Epoch 124/250\n",
            "736/736 [==============================] - 0s 100us/step - loss: 0.4992 - accuracy: 0.7554 - mae: 0.3419 - val_loss: 0.4878 - val_accuracy: 0.7663 - val_mae: 0.3337\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.48426\n",
            "Epoch 125/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5022 - accuracy: 0.7391 - mae: 0.3422 - val_loss: 0.4859 - val_accuracy: 0.7717 - val_mae: 0.3342\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.48426\n",
            "Epoch 126/250\n",
            "736/736 [==============================] - 0s 104us/step - loss: 0.5206 - accuracy: 0.7378 - mae: 0.3517 - val_loss: 0.4884 - val_accuracy: 0.7772 - val_mae: 0.3365\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.48426\n",
            "Epoch 127/250\n",
            "736/736 [==============================] - 0s 100us/step - loss: 0.5111 - accuracy: 0.7228 - mae: 0.3480 - val_loss: 0.4965 - val_accuracy: 0.7446 - val_mae: 0.3386\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.48426\n",
            "Epoch 128/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5214 - accuracy: 0.7405 - mae: 0.3554 - val_loss: 0.5338 - val_accuracy: 0.7500 - val_mae: 0.3569\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.48426\n",
            "Epoch 129/250\n",
            "736/736 [==============================] - 0s 102us/step - loss: 0.5176 - accuracy: 0.7283 - mae: 0.3486 - val_loss: 0.4904 - val_accuracy: 0.7554 - val_mae: 0.3343\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.48426\n",
            "Epoch 130/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5008 - accuracy: 0.7541 - mae: 0.3420 - val_loss: 0.4802 - val_accuracy: 0.7826 - val_mae: 0.3272\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.48426 to 0.48021, saving model to /tmp/model2.hdf5\n",
            "Epoch 131/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5140 - accuracy: 0.7473 - mae: 0.3474 - val_loss: 0.4888 - val_accuracy: 0.7391 - val_mae: 0.3363\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.48021\n",
            "Epoch 132/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5187 - accuracy: 0.7418 - mae: 0.3481 - val_loss: 0.4827 - val_accuracy: 0.7609 - val_mae: 0.3320\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.48021\n",
            "Epoch 133/250\n",
            "736/736 [==============================] - 0s 84us/step - loss: 0.4962 - accuracy: 0.7459 - mae: 0.3390 - val_loss: 0.5045 - val_accuracy: 0.7391 - val_mae: 0.3425\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.48021\n",
            "Epoch 134/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.4989 - accuracy: 0.7405 - mae: 0.3425 - val_loss: 0.4844 - val_accuracy: 0.7609 - val_mae: 0.3327\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.48021\n",
            "Epoch 135/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5142 - accuracy: 0.7269 - mae: 0.3480 - val_loss: 0.4941 - val_accuracy: 0.7772 - val_mae: 0.3347\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.48021\n",
            "Epoch 136/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5043 - accuracy: 0.7405 - mae: 0.3438 - val_loss: 0.4816 - val_accuracy: 0.7554 - val_mae: 0.3299\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.48021\n",
            "Epoch 137/250\n",
            "736/736 [==============================] - 0s 98us/step - loss: 0.5095 - accuracy: 0.7323 - mae: 0.3459 - val_loss: 0.4949 - val_accuracy: 0.7283 - val_mae: 0.3390\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.48021\n",
            "Epoch 138/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5182 - accuracy: 0.7351 - mae: 0.3454 - val_loss: 0.4787 - val_accuracy: 0.7772 - val_mae: 0.3219\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.48021 to 0.47868, saving model to /tmp/model2.hdf5\n",
            "Epoch 139/250\n",
            "736/736 [==============================] - 0s 84us/step - loss: 0.5089 - accuracy: 0.7364 - mae: 0.3461 - val_loss: 0.4862 - val_accuracy: 0.7609 - val_mae: 0.3322\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.47868\n",
            "Epoch 140/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5101 - accuracy: 0.7391 - mae: 0.3462 - val_loss: 0.4848 - val_accuracy: 0.7772 - val_mae: 0.3303\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.47868\n",
            "Epoch 141/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5077 - accuracy: 0.7310 - mae: 0.3438 - val_loss: 0.4802 - val_accuracy: 0.7663 - val_mae: 0.3280\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.47868\n",
            "Epoch 142/250\n",
            "736/736 [==============================] - 0s 103us/step - loss: 0.4920 - accuracy: 0.7418 - mae: 0.3375 - val_loss: 0.4881 - val_accuracy: 0.7446 - val_mae: 0.3320\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.47868\n",
            "Epoch 143/250\n",
            "736/736 [==============================] - 0s 88us/step - loss: 0.5156 - accuracy: 0.7364 - mae: 0.3454 - val_loss: 0.4866 - val_accuracy: 0.7609 - val_mae: 0.3296\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.47868\n",
            "Epoch 144/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5077 - accuracy: 0.7364 - mae: 0.3451 - val_loss: 0.4858 - val_accuracy: 0.7500 - val_mae: 0.3321\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.47868\n",
            "Epoch 145/250\n",
            "736/736 [==============================] - 0s 84us/step - loss: 0.5110 - accuracy: 0.7201 - mae: 0.3434 - val_loss: 0.4896 - val_accuracy: 0.7391 - val_mae: 0.3345\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.47868\n",
            "Epoch 146/250\n",
            "736/736 [==============================] - 0s 87us/step - loss: 0.5149 - accuracy: 0.7296 - mae: 0.3436 - val_loss: 0.5004 - val_accuracy: 0.7500 - val_mae: 0.3403\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.47868\n",
            "Epoch 147/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5239 - accuracy: 0.7323 - mae: 0.3505 - val_loss: 0.4949 - val_accuracy: 0.7772 - val_mae: 0.3311\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.47868\n",
            "Epoch 148/250\n",
            "736/736 [==============================] - 0s 109us/step - loss: 0.5241 - accuracy: 0.7405 - mae: 0.3471 - val_loss: 0.4966 - val_accuracy: 0.7663 - val_mae: 0.3371\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.47868\n",
            "Epoch 149/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5025 - accuracy: 0.7405 - mae: 0.3387 - val_loss: 0.4816 - val_accuracy: 0.7772 - val_mae: 0.3289\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.47868\n",
            "Epoch 150/250\n",
            "736/736 [==============================] - 0s 109us/step - loss: 0.5324 - accuracy: 0.7391 - mae: 0.3518 - val_loss: 0.4889 - val_accuracy: 0.7880 - val_mae: 0.3297\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.47868\n",
            "Epoch 151/250\n",
            "736/736 [==============================] - 0s 105us/step - loss: 0.5036 - accuracy: 0.7215 - mae: 0.3449 - val_loss: 0.4862 - val_accuracy: 0.7717 - val_mae: 0.3300\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.47868\n",
            "Epoch 152/250\n",
            "736/736 [==============================] - 0s 110us/step - loss: 0.5174 - accuracy: 0.7228 - mae: 0.3456 - val_loss: 0.4972 - val_accuracy: 0.7554 - val_mae: 0.3398\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.47868\n",
            "Epoch 153/250\n",
            "736/736 [==============================] - 0s 101us/step - loss: 0.5016 - accuracy: 0.7228 - mae: 0.3450 - val_loss: 0.4876 - val_accuracy: 0.7880 - val_mae: 0.3272\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.47868\n",
            "Epoch 154/250\n",
            "736/736 [==============================] - 0s 88us/step - loss: 0.5050 - accuracy: 0.7418 - mae: 0.3423 - val_loss: 0.4857 - val_accuracy: 0.7337 - val_mae: 0.3343\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.47868\n",
            "Epoch 155/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.4888 - accuracy: 0.7446 - mae: 0.3389 - val_loss: 0.5146 - val_accuracy: 0.7663 - val_mae: 0.3376\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.47868\n",
            "Epoch 156/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5057 - accuracy: 0.7459 - mae: 0.3395 - val_loss: 0.4763 - val_accuracy: 0.7500 - val_mae: 0.3243\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.47868 to 0.47634, saving model to /tmp/model2.hdf5\n",
            "Epoch 157/250\n",
            "736/736 [==============================] - 0s 115us/step - loss: 0.5008 - accuracy: 0.7446 - mae: 0.3386 - val_loss: 0.4852 - val_accuracy: 0.7717 - val_mae: 0.3315\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.47634\n",
            "Epoch 158/250\n",
            "736/736 [==============================] - 0s 111us/step - loss: 0.5047 - accuracy: 0.7432 - mae: 0.3436 - val_loss: 0.4810 - val_accuracy: 0.7880 - val_mae: 0.3264\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.47634\n",
            "Epoch 159/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5094 - accuracy: 0.7446 - mae: 0.3440 - val_loss: 0.4784 - val_accuracy: 0.7772 - val_mae: 0.3279\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.47634\n",
            "Epoch 160/250\n",
            "736/736 [==============================] - 0s 108us/step - loss: 0.5032 - accuracy: 0.7418 - mae: 0.3429 - val_loss: 0.4810 - val_accuracy: 0.7880 - val_mae: 0.3256\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.47634\n",
            "Epoch 161/250\n",
            "736/736 [==============================] - 0s 105us/step - loss: 0.5055 - accuracy: 0.7364 - mae: 0.3398 - val_loss: 0.4873 - val_accuracy: 0.7609 - val_mae: 0.3283\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.47634\n",
            "Epoch 162/250\n",
            "736/736 [==============================] - 0s 113us/step - loss: 0.4990 - accuracy: 0.7391 - mae: 0.3414 - val_loss: 0.4898 - val_accuracy: 0.7500 - val_mae: 0.3319\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.47634\n",
            "Epoch 163/250\n",
            "736/736 [==============================] - 0s 99us/step - loss: 0.4963 - accuracy: 0.7527 - mae: 0.3382 - val_loss: 0.4754 - val_accuracy: 0.7826 - val_mae: 0.3200\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.47634 to 0.47543, saving model to /tmp/model2.hdf5\n",
            "Epoch 164/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5289 - accuracy: 0.7323 - mae: 0.3429 - val_loss: 0.4729 - val_accuracy: 0.7772 - val_mae: 0.3192\n",
            "\n",
            "Epoch 00164: val_loss improved from 0.47543 to 0.47289, saving model to /tmp/model2.hdf5\n",
            "Epoch 165/250\n",
            "736/736 [==============================] - 0s 102us/step - loss: 0.5079 - accuracy: 0.7310 - mae: 0.3437 - val_loss: 0.4872 - val_accuracy: 0.7772 - val_mae: 0.3313\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.47289\n",
            "Epoch 166/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5197 - accuracy: 0.7310 - mae: 0.3473 - val_loss: 0.4764 - val_accuracy: 0.7609 - val_mae: 0.3261\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.47289\n",
            "Epoch 167/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.4982 - accuracy: 0.7459 - mae: 0.3348 - val_loss: 0.4833 - val_accuracy: 0.7500 - val_mae: 0.3332\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.47289\n",
            "Epoch 168/250\n",
            "736/736 [==============================] - 0s 100us/step - loss: 0.5090 - accuracy: 0.7310 - mae: 0.3447 - val_loss: 0.4878 - val_accuracy: 0.7772 - val_mae: 0.3290\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.47289\n",
            "Epoch 169/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5117 - accuracy: 0.7323 - mae: 0.3473 - val_loss: 0.4838 - val_accuracy: 0.7772 - val_mae: 0.3271\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.47289\n",
            "Epoch 170/250\n",
            "736/736 [==============================] - 0s 93us/step - loss: 0.5116 - accuracy: 0.7337 - mae: 0.3419 - val_loss: 0.5262 - val_accuracy: 0.7391 - val_mae: 0.3472\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.47289\n",
            "Epoch 171/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5111 - accuracy: 0.7296 - mae: 0.3412 - val_loss: 0.4871 - val_accuracy: 0.7337 - val_mae: 0.3286\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.47289\n",
            "Epoch 172/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5015 - accuracy: 0.7418 - mae: 0.3406 - val_loss: 0.4894 - val_accuracy: 0.7446 - val_mae: 0.3319\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.47289\n",
            "Epoch 173/250\n",
            "736/736 [==============================] - 0s 92us/step - loss: 0.5138 - accuracy: 0.7418 - mae: 0.3479 - val_loss: 0.5066 - val_accuracy: 0.7283 - val_mae: 0.3393\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.47289\n",
            "Epoch 174/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5111 - accuracy: 0.7391 - mae: 0.3454 - val_loss: 0.4835 - val_accuracy: 0.7500 - val_mae: 0.3299\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.47289\n",
            "Epoch 175/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.4884 - accuracy: 0.7378 - mae: 0.3358 - val_loss: 0.4884 - val_accuracy: 0.7391 - val_mae: 0.3347\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.47289\n",
            "Epoch 176/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5105 - accuracy: 0.7405 - mae: 0.3457 - val_loss: 0.4771 - val_accuracy: 0.7500 - val_mae: 0.3297\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.47289\n",
            "Epoch 177/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.5085 - accuracy: 0.7418 - mae: 0.3424 - val_loss: 0.4952 - val_accuracy: 0.7228 - val_mae: 0.3415\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.47289\n",
            "Epoch 178/250\n",
            "736/736 [==============================] - 0s 90us/step - loss: 0.5058 - accuracy: 0.7514 - mae: 0.3427 - val_loss: 0.4846 - val_accuracy: 0.7880 - val_mae: 0.3276\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.47289\n",
            "Epoch 179/250\n",
            "736/736 [==============================] - 0s 101us/step - loss: 0.5214 - accuracy: 0.7255 - mae: 0.3498 - val_loss: 0.4760 - val_accuracy: 0.7554 - val_mae: 0.3255\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.47289\n",
            "Epoch 180/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5032 - accuracy: 0.7541 - mae: 0.3366 - val_loss: 0.4726 - val_accuracy: 0.7609 - val_mae: 0.3237\n",
            "\n",
            "Epoch 00180: val_loss improved from 0.47289 to 0.47262, saving model to /tmp/model2.hdf5\n",
            "Epoch 181/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5323 - accuracy: 0.7296 - mae: 0.3496 - val_loss: 0.4782 - val_accuracy: 0.7772 - val_mae: 0.3243\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.47262\n",
            "Epoch 182/250\n",
            "736/736 [==============================] - 0s 107us/step - loss: 0.5060 - accuracy: 0.7391 - mae: 0.3443 - val_loss: 0.4852 - val_accuracy: 0.7554 - val_mae: 0.3334\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.47262\n",
            "Epoch 183/250\n",
            "736/736 [==============================] - 0s 95us/step - loss: 0.5026 - accuracy: 0.7541 - mae: 0.3420 - val_loss: 0.4772 - val_accuracy: 0.7880 - val_mae: 0.3205\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.47262\n",
            "Epoch 184/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.4894 - accuracy: 0.7351 - mae: 0.3356 - val_loss: 0.4832 - val_accuracy: 0.7446 - val_mae: 0.3309\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.47262\n",
            "Epoch 185/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5070 - accuracy: 0.7378 - mae: 0.3436 - val_loss: 0.4869 - val_accuracy: 0.7500 - val_mae: 0.3278\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.47262\n",
            "Epoch 186/250\n",
            "736/736 [==============================] - 0s 104us/step - loss: 0.4919 - accuracy: 0.7473 - mae: 0.3366 - val_loss: 0.4992 - val_accuracy: 0.7663 - val_mae: 0.3311\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.47262\n",
            "Epoch 187/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5062 - accuracy: 0.7405 - mae: 0.3383 - val_loss: 0.5058 - val_accuracy: 0.7717 - val_mae: 0.3339\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.47262\n",
            "Epoch 188/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.5177 - accuracy: 0.7242 - mae: 0.3422 - val_loss: 0.4752 - val_accuracy: 0.7554 - val_mae: 0.3248\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.47262\n",
            "Epoch 189/250\n",
            "736/736 [==============================] - 0s 86us/step - loss: 0.4958 - accuracy: 0.7310 - mae: 0.3390 - val_loss: 0.4814 - val_accuracy: 0.7717 - val_mae: 0.3270\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.47262\n",
            "Epoch 190/250\n",
            "736/736 [==============================] - 0s 98us/step - loss: 0.5031 - accuracy: 0.7391 - mae: 0.3392 - val_loss: 0.5013 - val_accuracy: 0.7337 - val_mae: 0.3366\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.47262\n",
            "Epoch 191/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.4962 - accuracy: 0.7337 - mae: 0.3374 - val_loss: 0.4920 - val_accuracy: 0.7446 - val_mae: 0.3311\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.47262\n",
            "Epoch 192/250\n",
            "736/736 [==============================] - 0s 87us/step - loss: 0.5144 - accuracy: 0.7432 - mae: 0.3429 - val_loss: 0.4798 - val_accuracy: 0.7772 - val_mae: 0.3284\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.47262\n",
            "Epoch 193/250\n",
            "736/736 [==============================] - 0s 88us/step - loss: 0.4943 - accuracy: 0.7446 - mae: 0.3391 - val_loss: 0.4789 - val_accuracy: 0.7446 - val_mae: 0.3268\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.47262\n",
            "Epoch 194/250\n",
            "736/736 [==============================] - 0s 97us/step - loss: 0.4939 - accuracy: 0.7568 - mae: 0.3379 - val_loss: 0.4862 - val_accuracy: 0.7826 - val_mae: 0.3208\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.47262\n",
            "Epoch 195/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.4827 - accuracy: 0.7446 - mae: 0.3267 - val_loss: 0.4746 - val_accuracy: 0.7609 - val_mae: 0.3208\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.47262\n",
            "Epoch 196/250\n",
            "736/736 [==============================] - 0s 85us/step - loss: 0.4912 - accuracy: 0.7378 - mae: 0.3316 - val_loss: 0.4982 - val_accuracy: 0.7283 - val_mae: 0.3406\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.47262\n",
            "Epoch 197/250\n",
            "736/736 [==============================] - 0s 96us/step - loss: 0.5206 - accuracy: 0.7418 - mae: 0.3391 - val_loss: 0.4776 - val_accuracy: 0.7554 - val_mae: 0.3200\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.47262\n",
            "Epoch 198/250\n",
            "736/736 [==============================] - 0s 97us/step - loss: 0.5068 - accuracy: 0.7446 - mae: 0.3377 - val_loss: 0.4812 - val_accuracy: 0.7826 - val_mae: 0.3226\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.47262\n",
            "Epoch 199/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5160 - accuracy: 0.7364 - mae: 0.3463 - val_loss: 0.4845 - val_accuracy: 0.7554 - val_mae: 0.3272\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.47262\n",
            "Epoch 200/250\n",
            "736/736 [==============================] - 0s 83us/step - loss: 0.5081 - accuracy: 0.7310 - mae: 0.3409 - val_loss: 0.4800 - val_accuracy: 0.7337 - val_mae: 0.3261\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.47262\n",
            "Epoch 201/250\n",
            "736/736 [==============================] - 0s 84us/step - loss: 0.4954 - accuracy: 0.7351 - mae: 0.3348 - val_loss: 0.4794 - val_accuracy: 0.7337 - val_mae: 0.3292\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.47262\n",
            "Epoch 202/250\n",
            "736/736 [==============================] - 0s 94us/step - loss: 0.5041 - accuracy: 0.7405 - mae: 0.3407 - val_loss: 0.4808 - val_accuracy: 0.7500 - val_mae: 0.3306\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.47262\n",
            "Epoch 203/250\n",
            "736/736 [==============================] - 0s 98us/step - loss: 0.4931 - accuracy: 0.7432 - mae: 0.3380 - val_loss: 0.4854 - val_accuracy: 0.7446 - val_mae: 0.3345\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.47262\n",
            "Epoch 204/250\n",
            "736/736 [==============================] - 0s 91us/step - loss: 0.4897 - accuracy: 0.7473 - mae: 0.3338 - val_loss: 0.4784 - val_accuracy: 0.7446 - val_mae: 0.3301\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.47262\n",
            "Epoch 205/250\n",
            "736/736 [==============================] - 0s 89us/step - loss: 0.4956 - accuracy: 0.7378 - mae: 0.3394 - val_loss: 0.4756 - val_accuracy: 0.7717 - val_mae: 0.3222\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.47262\n",
            "Epoch 00205: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jHBktZ8oqL",
        "colab_type": "code",
        "outputId": "88ec569d-ad55-4671-8fd3-12d0898ed32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('/tmp/accuracy_train_val_2.png')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n",
        "plt.savefig('/tmp/loss_train_val_2.png')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFU36cWXdj8v",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the Performance\n",
        "We use the same metrics as that will be used for the test set.  \n",
        "[F1 score](https://en.wikipedia.org/wiki/F1_score) are the metrics for this challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5sUZRprdj8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# precision = precision_score(y_val,y_pred,average='micro')\n",
        "# recall = recall_score(y_val,y_pred,average='micro')\n",
        "# accuracy = accuracy_score(y_val,y_pred)\n",
        "# f1 = f1_score(y_val,y_pred,average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xaJRslHdj82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Accuracy of the model is :\" ,accuracy)\n",
        "# print(\"Recall of the model is :\" ,recall)\n",
        "# print(\"Precision of the model is :\" ,precision)\n",
        "# print(\"F1 score of the model is :\" ,f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqMubiITdj88",
        "colab_type": "text"
      },
      "source": [
        "# Prediction on Evaluation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3rk3XmPi2S",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yPQtUcdj9E",
        "colab_type": "text"
      },
      "source": [
        "## Predict Test Set\n",
        "Time for the moment of truth! Predict on test set and time to make the submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9SYYFxEdj9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission = classifier.predict(final_test)\n",
        "best_model.load_weights('/tmp/model2.hdf5') #best model weights saved here\n",
        "submission = best_model.predict_classes(final_test).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G51dI9htdj9J",
        "colab_type": "text"
      },
      "source": [
        "## Save the prediction to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Z6khKFdj9O",
        "colab_type": "text"
      },
      "source": [
        "Note: Do take a look at the submission format.The submission file should contain a header.For eg here it is \"label\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDUlw8RdQiPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(submission)\n",
        "\n",
        "submission.to_csv('/tmp/submission.csv',header=['label'],index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdCMmwtTTqNg",
        "colab_type": "code",
        "outputId": "8b7ba3e0-7506-489f-e8b9-59961cfee704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  1\n",
              "2  0\n",
              "3  1\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W7a3HfLdj9P",
        "colab_type": "text"
      },
      "source": [
        "## To download the generated csv in colab run the below command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzjJcuOdj9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission = classifier.predict(final_test)\n",
        "# df_sub = pd.DataFrame({'ID': id_test, 'y': y_test})\n",
        "from google.colab import files\n",
        "files.download('/tmp/submission.csv') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s0g1IoBQifc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "My final submission :- https://www.aicrowd.com/8299814dae2a\n",
        "\n",
        "---\n",
        "References:-\n",
        "\n",
        "\n",
        "1.   https://medium.com/datadriveninvestor/hyperparameter-tuning-with-deep-learning-grid-search-8630aa45b2da\n",
        "2.   https://www.kaggle.com/eikedehling/keras-nn-scaling-feature-selection-0-548/data\n",
        "3.   https://medium.com/@am.benatmane/keras-hyperparameter-tuning-using-sklearn-pipelines-grid-search-with-cross-validation-ccfc74b0ce9f\n",
        "4.   https://ai.stackexchange.com/questions/18206/what-kind-of-optimizer-is-suggested-to-use-for-binary-classification-of-similar\n",
        "\n",
        "\n",
        "Future Improvement :--> SVM , Ensemble methods , Tuning all parameters together.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d3tGWZRdj9V",
        "colab_type": "text"
      },
      "source": [
        "### Go to [platform](https://www.aicrowd.com/challenges/aicrowd-blitz-may-2020/problems/dibrd). Participate in the challenge and submit the submission.csv generated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku5x4rIFDeB7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}